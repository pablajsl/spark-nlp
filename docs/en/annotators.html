<!DOCTYPE html><html lang="en">
  <head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"><title>Annotators - Spark NLP</title><meta name="description" content="High Performance NLP with Apache Spark
">
<link rel="canonical" href="/docs/en/annotators"><link rel="alternate" type="application/rss+xml" title="Spark NLP" href="/feed.xml"><!-- start favicons snippet, use https://realfavicongenerator.net/ -->
<!---->
<!-- <link rel="apple-touch-icon" sizes="180x180" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="32x32" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="16x16" href="/fav.ico"> -->

<!---->
<!-- <link rel="manifest" href="/fav.ico"> --><link rel="mask-icon" href="/fav.ico" color="#fc4d50"><link rel="shortcut icon" href="/fav.ico">

<meta name="msapplication-TileColor" content="#ffc40d"><meta name="msapplication-config" content="/assets/browserconfig.xml">

<meta name="theme-color" content="#ffffff">
<!-- end favicons snippet --><link rel="stylesheet" href="/assets/css/main.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" ><!-- start custom head snippets -->
 <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700;800&display=swap" rel="stylesheet"> 
 <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
<!-- end custom head snippets -->
<script>(function() {
  window.isArray = function(val) {
    return Object.prototype.toString.call(val) === '[object Array]';
  };
  window.isString = function(val) {
    return typeof val === 'string';
  };

  window.decodeUrl = function(str) {
    return str ? decodeURIComponent(str.replace(/\+/g, '%20')) : '';
  };

  window.hasEvent = function(event) {
    return 'on'.concat(event) in window.document;
  };

  window.isOverallScroller = function(node) {
    return node === document.documentElement || node === document.body || node === window;
  };

  window.isFormElement = function(node) {
    var tagName = node.tagName;
    return tagName === 'INPUT' || tagName === 'SELECT' || tagName === 'TEXTAREA';
  };

  window.pageLoad = (function () {
    var loaded = false, cbs = [];
    window.addEventListener('load', function () {
      var i;
      loaded = true;
      if (cbs.length > 0) {
        for (i = 0; i < cbs.length; i++) {
          cbs[i]();
        }
      }
    });
    return {
      then: function(cb) {
        cb && (loaded ? cb() : (cbs.push(cb)));
      }
    };
  })();
})();
(function() {
  window.throttle = function(func, wait) {
    var args, result, thisArg, timeoutId, lastCalled = 0;

    function trailingCall() {
      lastCalled = new Date;
      timeoutId = null;
      result = func.apply(thisArg, args);
    }
    return function() {
      var now = new Date,
        remaining = wait - (now - lastCalled);

      args = arguments;
      thisArg = this;

      if (remaining <= 0) {
        clearTimeout(timeoutId);
        timeoutId = null;
        lastCalled = now;
        result = func.apply(thisArg, args);
      } else if (!timeoutId) {
        timeoutId = setTimeout(trailingCall, remaining);
      }
      return result;
    };
  };
})();
(function() {
  var Set = (function() {
    var add = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (data[i] === item) {
          return;
        }
      }
      this.size ++;
      data.push(item);
      return data;
    };

    var Set = function(data) {
      this.size = 0;
      this._data = [];
      var i;
      if (data.length > 0) {
        for (i = 0; i < data.length; i++) {
          add.call(this, data[i]);
        }
      }
    };
    Set.prototype.add = add;
    Set.prototype.get = function(index) { return this._data[index]; };
    Set.prototype.has = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (this.get(i) === item) {
          return true;
        }
      }
      return false;
    };
    Set.prototype.is = function(map) {
      if (map._data.length !== this._data.length) { return false; }
      var i, j, flag, tData = this._data, mData = map._data;
      for (i = 0; i < tData.length; i++) {
        for (flag = false, j = 0; j < mData.length; j++) {
          if (tData[i] === mData[j]) {
            flag = true;
            break;
          }
        }
        if (!flag) { return false; }
      }
      return true;
    };
    Set.prototype.values = function() {
      return this._data;
    };
    return Set;
  })();

  window.Lazyload = (function(doc) {
    var queue = {js: [], css: []}, sources = {js: {}, css: {}}, context = this;
    var createNode = function(name, attrs) {
      var node = doc.createElement(name), attr;
      for (attr in attrs) {
        if (attrs.hasOwnProperty(attr)) {
          node.setAttribute(attr, attrs[attr]);
        }
      }
      return node;
    };
    var end = function(type, url) {
      var s, q, qi, cbs, i, j, cur, val, flag;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        s[url] = true;
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (cur.urls.has(url)) {
            qi = cur, val = qi.urls.values();
            qi && (cbs = qi.callbacks);
            for (flag = true, j = 0; j < val.length; j++) {
              cur = val[j];
              if (!s[cur]) {
                flag = false;
              }
            }
            if (flag && cbs && cbs.length > 0) {
              for (j = 0; j < cbs.length; j++) {
                cbs[j].call(context);
              }
              qi.load = true;
            }
          }
        }
      }
    };
    var load = function(type, urls, callback) {
      var s, q, qi, node, i, cur,
        _urls = typeof urls === 'string' ? new Set([urls]) : new Set(urls), val, url;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (_urls.is(cur.urls)) {
            qi = cur;
            break;
          }
        }
        val = _urls.values();
        if (qi) {
          callback && (qi.load || qi.callbacks.push(callback));
          callback && (qi.load && callback());
        } else {
          q.push({
            urls: _urls,
            callbacks: callback ? [callback] : [],
            load: false
          });
          for (i = 0; i < val.length; i++) {
            node = null, url = val[i];
            if (s[url] === undefined) {
              (type === 'js' ) && (node = createNode('script', { src: url }));
              (type === 'css') && (node = createNode('link', { rel: 'stylesheet', href: url }));
              if (node) {
                node.onload = (function(type, url) {
                  return function() {
                    end(type, url);
                  };
                })(type, url);
                (doc.head || doc.body).appendChild(node);
                s[url] = false;
              }
            }
          }
        }
      }
    };
    return {
      js: function(url, callback) {
        load('js', url, callback);
      },
      css: function(url, callback) {
        load('css', url, callback);
      }
    };
  })(this.document);
})();
</script><script>
  (function() {
    var TEXT_VARIABLES = {
      version: '2.2.4',
      sources: {
        font_awesome: 'https://use.fontawesome.com/releases/v5.0.13/css/all.css',
        jquery: 'https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js',
        leancloud_js_sdk: '//cdn1.lncld.net/static/js/3.4.1/av-min.js',
        chart: 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js',
        gitalk: {
          js: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.js',
          css: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.css'
        },
        valine: 'https://unpkg.com/valine/dist/Valine.min.js',
        mathjax: 'https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML',
        mermaid: 'https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js'
      },
      site: {
        toc: {
          selectors: 'h1,h2,h3'
        }
      },
      paths: {
        search_js: '/assets/search.js'
      }
    };
    window.TEXT_VARIABLES = TEXT_VARIABLES;
  })();
</script></head>
  <body>
    <div class="root" data-is-touch="false">
      <div class="layout--page layout--page--sidebar clearfix js-page-root&nbsp; layout--page--aside">
  <div class="page__mask d-print-none js-page-mask js-sidebar-hide"></div>
  <div class="page__viewport">
    <div class="page__actions d-print-none">
      <div class="js-sidebar-show">
        <i class="fas fa-bars icon--show"></i>
      </div>
    </div>

    <div class="grid page__grid">

      <div class="page__sidebar d-print-none"><a title="High Performance NLP with Apache Spark
" href="/">
    <!--<svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
-->
</a><div class="sidebar-toc"><ul class="toc toc--navigator"><li class="toc-h1">Spark NLP</li><li class="toc-h2"><a href="/docs/en/quickstart">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/install">Install Spark NLP</a></li><li class="toc-h2"><a href="/docs/en/concepts">General Concepts</a></li><li class="toc-h2"><a href="/docs/en/transformers">Transformers</a></li><li class="toc-h2 active"><a href="/docs/en/annotators">Annotators</a></li><li class="toc-h2"><a href="/docs/en/auxiliary">Helpers</a></li><li class="toc-h2"><a href="/docs/en/pipelines">Pipelines</a></li><li class="toc-h2"><a href="/models">Models</a></li><li class="toc-h2"><a href="/docs/en/training">Training</a></li><li class="toc-h2"><a href="/api/">Scaladoc</a></li><li class="toc-h2"><a href="/docs/en/display">Spark NLP Display</a></li><li class="toc-h2"><a href="/docs/en/developers">Developers</a></li><li class="toc-h2"><a href="/docs/en/release_notes">Release Notes</a></li><li class="toc-h1">Annotation Lab</li><li class="toc-h2"><a href="/docs/en/alab">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/start_page">Start Page</a></li><li class="toc-h2"><a href="/docs/en/project_setup">Project Setup</a></li><li class="toc-h2"><a href="/docs/en/import">Import Documents</a></li><li class="toc-h2"><a href="/docs/en/tasks">Tasks</a></li><li class="toc-h2"><a href="/docs/en/annotation">Annotate</a></li><li class="toc-h2"><a href="/docs/en/export">Export Data</a></li><li class="toc-h2"><a href="/docs/en/workflow">Workflow Setup</a></li><li class="toc-h2"><a href="/docs/en/tutorials">Video Tutorials</a></li><li class="toc-h1">Spark NLP for Healthcare</li><li class="toc-h2"><a href="/docs/en/licensed_install">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/licensed_annotators">Annotators</a></li><li class="toc-h2"><a href="/docs/en/licensed_models">Models</a></li><li class="toc-h2"><a href="/docs/en/evaluation">Evaluation</a></li><li class="toc-h2"><a href="/licensed/api/">Scaladoc</a></li><li class="toc-h2"><a href="/docs/en/licensed_release_notes">Release Notes</a></li><li class="toc-h1">Spark OCR</li><li class="toc-h2"><a href="/docs/en/ocr">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/ocr_install">Installation</a></li><li class="toc-h2"><a href="/docs/en/ocr_pipeline_components">Pipeline components</a></li><li class="toc-h2"><a href="/docs/en/ocr_structures">Structures and helpers</a></li><li class="toc-h2"><a href="/docs/en/ocr_release_notes">Release notes</a></li></ul></div></div><div class="page__main js-page-main has-aside cell cell--auto">

      <div class="page__main-inner"><div class="page__header d-print-none"><header class="header"><div class="main">
      <div class="header__title">
        <a class="responsive_btn" href="#" id="responsive_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
        <div class="header__brand">
          <a title="High Performance NLP with Apache Spark
" href="https://www.johnsnowlabs.com" target="_blank"><svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
</a><!---->
            <!-- <a title="High Performance NLP with Apache Spark
" href="/">Spark NLP</a> -->
          <!---->
        </div><button class="button button--secondary button--circle search-button js-search-toggle"><i class="fas fa-search"></i></button></div><nav class="navigation top_navigation">
        <ul class="top-menu"><li class="navigation__item "><a href="/">Home</a></li><li class="navigation__item navigation__item--active"><a href="/docs/en/quickstart">Docs</a></li><li class="navigation__item "><a href="/learn">Learn</a></li><li class="navigation__item "><a href="/modelmain">Models</a></li><li class="navigation__item "><a href="/demo">Demo</a></li><li class="navigation__item "><a href="https://github.com/JohnSnowLabs/spark-nlp"><span style="color: #FF8A00;"><i class="fab fa-github fa-2x"></i></span></a></li><li class="navigation__item "><a href="https://join.slack.com/t/spark-nlp/shared_invite/enQtNjA4MTE2MDI1MDkxLWVjNWUzOGNlODg1Y2FkNGEzNDQ1NDJjMjc3Y2FkOGFmN2Q3ODIyZGVhMzU0NGM3NzRjNDkyZjZlZTQ0YzY1N2I"><span style="color: #FF8A00;"><i class="fab fa-slack-hash fa-2x"></i></span></a></li><li><button class="button button--secondary button--circle search-button js-search-toggle"><i class="fas fa-search"></i></button></li></ul>
      </nav><a class="responsive_btn" href="#" id="aside_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
    </div>
  </header>
</div><div class="page__content"><div class ="main"><div class="grid grid--reverse">

              <div class="col-aside d-print-none js-col-aside"><aside class="page__aside js-page-aside"><div class="toc-aside js-toc-root"></div></aside></div>

              <div class="col-main cell cell--auto"><!-- start custom main top snippet -->

<!-- end custom main top snippet --><article itemscope itemtype="http://schema.org/Article"><script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script><div class="article__header"><header><h1>Annotators</h1></header><span class="split-space">&nbsp;</span>
          <a class="edit-on-github"
            title="Edit on Github"
            href="https://github.com/johnsnowlabs/spark-nlp/tree/master/docs/en/annotators.md">
            <i class="far fa-edit"></i></a></div><meta itemprop="headline" content="Annotators"><meta itemprop="author" content=""/><div class="js-article-content"><div class="docs-wrapper">
<div class="layout--article"><!-- start custom article top snippet -->

<!-- end custom article top snippet --><div class="article__content" itemprop="articleBody"><div class="h3-box">

  <h2 id="how-to-read-this-section">How to read this section</h2>

  <p>All annotators in Spark NLP share a common interface, this is:</p>

  <ul>
    <li>Annotation -&gt; <code class="language-plaintext highlighter-rouge">Annotation(annotatorType, begin, end, result, meta-data,
embeddings)</code></li>
    <li>AnnotatorType -&gt; some annotators share a type. This is not only
figurative, but also tells about the structure of the <code class="language-plaintext highlighter-rouge">metadata</code> map in
the Annotation. This is the one referred in the input and output of
annotators.</li>
    <li>Inputs -&gt; Represents how many and which annotator types are expected
in <code class="language-plaintext highlighter-rouge">setInputCols</code>. These are column names of output of other annotators
in the dataframe.</li>
    <li>Output -&gt; Represents the type of the output in the column
<code class="language-plaintext highlighter-rouge">setOutputCol</code>.</li>
  </ul>

  <p>There are two types of annotators:</p>

  <ul>
    <li>Approach -&gt; AnnotatorApproach extend Estimators, which are meant to be trained through <code class="language-plaintext highlighter-rouge">fit()</code></li>
    <li>Model -&gt; AnnotatorModel extend from Transfromers, which are meant to transform dataframes through <code class="language-plaintext highlighter-rouge">transform()</code></li>
  </ul>

  <p><code class="language-plaintext highlighter-rouge">Model</code> suffix is explicitly stated when the annotator is the result of a training process. Some annotators, such as <code class="language-plaintext highlighter-rouge">Tokenizer</code> are transformers, but do not contain the word Model since they are not trained annotators.</p>

  <p><code class="language-plaintext highlighter-rouge">Model</code> annotators have a <code class="language-plaintext highlighter-rouge">pretrained()</code> on it’s static object, to retrieve the public pretrained version of a model.</p>

  <ul>
    <li>pretrained(name, language, extra_location) -&gt; by default, pretrained will bring a default model, sometimes we offer more than one model, in this case, you may have to use name, language or extra location to download them.</li>
  </ul>

  <p>The types are:</p>

  <ul>
    <li>DOCUMENT = “document”</li>
    <li>TOKEN = “token”</li>
    <li>WORDPIECE = “wordpiece”</li>
    <li>WORD_EMBEDDINGS = “word_embeddings”</li>
    <li>SENTENCE_EMBEDDINGS = “sentence_embeddings”</li>
    <li>CATEGORY = “category”</li>
    <li>DATE = “date”</li>
    <li>ENTITY = “entity”</li>
    <li>SENTIMENT = “sentiment”</li>
    <li>POS = “pos”</li>
    <li>CHUNK = “chunk”</li>
    <li>NAMED_ENTITY = “named_entity”</li>
    <li>NEGEX = “negex”</li>
    <li>DEPENDENCY = “dependency”</li>
    <li>LABELED_DEPENDENCY = “labeled_dependency”</li>
    <li>LANGUAGE = “language”</li>
    <li>KEYWORD = “keyword”</li>
  </ul>

  <table class="table-model-big">
    <thead>
      <tr>
        <th>Annotator</th>
        <th>Description</th>
        <th>Version</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Tokenizer</td>
        <td>Identifies tokens with tokenization open standards</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>WordSegmenter</td>
        <td>Trainable annotator for word segmentation of languages without any rule-based tokenization such as Chinese, Japanese, or Korean</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>Normalizer</td>
        <td>Removes all dirty characters from text</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>DocumentNormalizer</td>
        <td>Cleaning content from HTML or XML documents</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>Stemmer</td>
        <td>Returns hard-stems out of words with the objective of retrieving the meaningful part of the word</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>Lemmatizer</td>
        <td>Retrieves lemmas out of words with the objective of returning a base dictionary word</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>StopWordsCleaner</td>
        <td>This annotator excludes from a sequence of strings (e.g. the output of a Tokenizer, Normalizer, Lemmatizer, and Stemmer) and drops all the stop words from the input sequences</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>RegexMatcher</td>
        <td>Uses a reference file to match a set of regular expressions and put them inside a provided key.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>TextMatcher</td>
        <td>Annotator to match entire phrases (by token) provided in a file against a Document</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>Chunker</td>
        <td>Matches a pattern of part-of-speech tags in order to return meaningful phrases from document</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>NGramGenerator</td>
        <td>integrates Spark ML NGram function into Spark ML with a new cumulative feature to also generate range ngrams like the scikit-learn library</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>DateMatcher</td>
        <td>Reads from different forms of date and time expressions and converts them to a provided date format</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>MultiDateMatcher</td>
        <td>Reads from multiple different forms of date and time expressions and converts them to a provided date format</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>SentenceDetector</td>
        <td>Finds sentence bounds in raw text. Applies rules from Pragmatic Segmenter</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>POSTagger</td>
        <td>Sets a Part-Of-Speech tag to each word within a sentence.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>ViveknSentimentDetector</td>
        <td>Scores a sentence for a sentiment</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>SentimentDetector</td>
        <td>Scores a sentence for a sentiment</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>WordEmbeddings</td>
        <td>Word Embeddings lookup annotator that maps tokens to vectors</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>BertEmbeddings</td>
        <td>BERT (Bidirectional Encoder Representations from Transformers) provides dense vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>BertSentenceEmbeddings</td>
        <td>This annotator generates sentence embeddings from all BERT models</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>ElmoEmbeddings</td>
        <td>Computes contextualized word representations using character-based word representations and bidirectional LSTMs</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>AlbertEmbeddings</td>
        <td>Computes contextualized word representations using “A Lite” implementation of BERT algorithm by applying parameter-reduction techniques</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>XlnetEmbeddings</td>
        <td>Computes contextualized word representations using combination of Autoregressive Language Model and Permutation Language Model</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>UniversalSentenceEncoder</td>
        <td>Encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>SentenceEmbeddings</td>
        <td>utilizes WordEmbeddings or BertEmbeddings to generate sentence or document embeddings</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>ChunkEmbeddings</td>
        <td>utilizes WordEmbeddings or BertEmbeddings to generate chunk embeddings from either Chunker, NGramGenerator, or NerConverter outputs</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>ClassifierDL</td>
        <td>Multi-class Text Classification. ClassifierDL uses the state-of-the-art Universal Sentence Encoder as an input for text classifications. The ClassifierDL annotator uses a deep learning model (DNNs) we have built inside TensorFlow and supports up to 100 classes</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>MultiClassifierDL</td>
        <td>Multi-label Text Classification. MultiClassifierDL uses a Bidirectional GRU with Convolution model that we have built inside TensorFlow and supports up to 100 classes.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>SentimentDL</td>
        <td>Multi-class Sentiment Analysis Annotator. SentimentDL is an annotator for multi-class sentiment analysis. This annotator comes with 2 available pre-trained models trained on IMDB and Twitter datasets</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>T5Transformer</td>
        <td>for Text-To-Text Transfer Transformer (Google T5) models to achieve state-of-the-art results on multiple NLP tasks such as Translation, Summarization, Question Answering, Sentence Similarity, and so on</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>MarianTransformer</td>
        <td>Neural Machine Translation based on MarianNMT models being developed by the Microsoft Translator team</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>LanguageDetectorDL</td>
        <td>State-of-the-art language detection and identification annotator trained by using TensorFlow/keras neural networks</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>YakeModel</td>
        <td>Yake is an Unsupervised, Corpus-Independent, Domain and Language-Independent and Single-Document keyword extraction algorithm.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>NerDL</td>
        <td>Named Entity recognition annotator allows for a generic model to be trained by utilizing a deep learning algorithm (Char CNNs - BiLSTM - CRF - word embeddings)</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>NerCrf</td>
        <td>Named Entity recognition annotator allows for a generic model to be trained by utilizing a CRF machine learning algorithm</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>NorvigSweeting SpellChecker</td>
        <td>This annotator retrieves tokens and makes corrections automatically if not found in an English dictionary</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>SymmetricDelete SpellChecker</td>
        <td>This spell checker is inspired on Symmetric Delete algorithm</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>Context SpellChecker</td>
        <td>Implements Noisy Channel Model Spell Algorithm. Correction candidates are extracted combining context information and word information</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>DependencyParser</td>
        <td>Unlabeled parser that finds a grammatical relation between two words in a sentence</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>TypedDependencyParser</td>
        <td>Labeled parser that finds a grammatical relation between two words in a sentence</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td>PubTator reader</td>
        <td>Converts automatic annotations of the biomedical datasets into Spark DataFrame</td>
        <td>Opensource</td>
      </tr>
    </tbody>
  </table>

</div>

<div class="h3-box">

  <h2 id="tokenizer">Tokenizer</h2>

  <p>Identifies tokens with tokenization open standards. A few rules will help customizing it if defaults do not fit user needs.<br />
<strong>Output type:</strong> Token<br />
<strong>Input types:</strong> Document<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Tokenizer.scala">Tokenizer</a>|<a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/TokenizerModel.scala">TokenizerModel</a><br />
<strong>Functions:</strong></p>

  <ul>
    <li>setExceptions(StringArray): List of tokens to not alter at all. Allows composite tokens like two worded tokens that the user may not want to split.</li>
    <li>addException(String): Add a single exception</li>
    <li>setExceptionsPath(String): Path to txt file with list of token exceptions</li>
    <li>caseSensitiveExceptions(bool): Whether to follow case sensitiveness for matching exceptions in text</li>
    <li>contextChars(StringArray): List of 1 character string to rip off from tokens, such as parenthesis or question marks. Ignored if using prefix, infix or suffix patterns.</li>
    <li>splitChars(StringArray): List of 1 character string to split tokens inside, such as hyphens. Ignored if using infix, prefix or suffix patterns.</li>
    <li>splitPattern (String): pattern to separate from the inside of tokens. takes priority over splitChars.</li>
    <li>setTargetPattern: Basic regex rule to identify a candidate for tokenization. Defaults to <code class="language-plaintext highlighter-rouge">\\S+</code> which means anything not a space</li>
    <li>setSuffixPattern: Regex to identify subtokens that are in the end of the token. Regex has to end with <code class="language-plaintext highlighter-rouge">\\z</code> and must contain groups (). Each group will become a separate token within the prefix. Defaults to non-letter characters. e.g. quotes or parenthesis</li>
    <li>setPrefixPattern: Regex to identify subtokens that come in the beginning of the token. Regex has to start with <code class="language-plaintext highlighter-rouge">\\A</code> and must contain groups (). Each group will become a separate token within the prefix. Defaults to non-letter characters. e.g. quotes or parenthesis</li>
    <li>addInfixPattern: Add an extension pattern regex with groups to the top of the rules (will target first, from more specific to the more general).</li>
    <li>minLength: Set the minimum allowed legth for each token</li>
    <li>maxLength: Set the maximum allowed legth for each token</li>
  </ul>

  <p><strong>Note:</strong> all these APIs receive regular expressions so please make sure that you escape special characters according to Java conventions.</p>

  <p><strong>Example:</strong></p>

  <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Tokenizer">Tokenizer</a> Scala docs for more details on the API.</p>

  <div class="tabs-box">

    <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setSplitChars</span><span class="p">([</span><span class="s">'-'</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setContextChars</span><span class="p">([</span><span class="s">'('</span><span class="p">,</span> <span class="s">')'</span><span class="p">,</span> <span class="s">'?'</span><span class="p">,</span> <span class="s">'!'</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">addException</span><span class="p">(</span><span class="s">"New York"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">addException</span><span class="p">(</span><span class="s">"e-mail"</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setContextChars</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"("</span><span class="o">,</span> <span class="s">")"</span><span class="o">,</span> <span class="s">"?"</span><span class="o">,</span> <span class="s">"!"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setSplitChars</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="sc">'-'</span><span class="o">))</span>
    <span class="o">.</span><span class="py">addException</span><span class="o">(</span><span class="s">"New York"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">addException</span><span class="o">(</span><span class="s">"e-mail"</span><span class="o">)</span>
</code></pre></div>    </div>

  </div>
</div>
<div class="h3-box">

  <h2 id="documentnormalizer-text-cleaning">DocumentNormalizer (Text cleaning)</h2>

  <p>Annotator which normalizes raw text from tagged text, e.g. scraped web pages or xml documents, from document type columns into Sentence.<br />
<strong>Output type:</strong> Document<br />
<strong>Input types:</strong> Document<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/DocumentNormalizer.scala">DocumentNormalizer</a><br />
<strong>Functions:</strong></p>

  <ul>
    <li>setCleanupPatterns(patterns): normalization regex patterns which match will be removed from document. Defaults is “&lt;[^&gt;]*&gt;”.</li>
    <li>setLowercase(value): whether to convert strings to lowercase, default false</li>
    <li>setRemovalPolicy(policy): removalPolicy to remove pattern from text</li>
  </ul>

  <p><strong>Example:</strong></p>

  <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Normalizer">DocumentNormalizer</a> Scala docs for more details on the API.</p>

  <div class="tabs-box">

    <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">documentNormalizer</span> <span class="o">=</span> <span class="n">DocumentNormalizer</span><span class="p">()</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalizedDocument"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setCleanupPatterns</span><span class="p">(</span><span class="n">cleanUpPatterns</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setRemovalPolicy</span><span class="p">(</span><span class="n">removalPolicy</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">val</span> <span class="nv">documentNormalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentNormalizer</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalizedDocument"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setCleanupPatterns</span><span class="o">(</span><span class="n">cleanUpPatterns</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setRemovalPolicy</span><span class="o">(</span><span class="n">removalPolicy</span><span class="o">)</span>
</code></pre></div>    </div>

  </div>
</div>
<div class="h3-box">

  <h2 id="normalizer-text-cleaning">Normalizer (Text cleaning)</h2>

  <p>Removes all dirty characters from text following a regex pattern and transforms words based on a provided dictionary<br />
<strong>Output type:</strong> Token<br />
<strong>Input types:</strong> Token<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Normalizer.scala">Normalizer</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/NormalizerModel.scala">NormalizerModel</a><br />
<strong>Functions:</strong></p>

  <ul>
    <li>setCleanupPatterns(patterns): Regular expressions list for normalization, defaults [^A-Za-z]</li>
    <li>setLowercase(value): lowercase tokens, default true</li>
    <li>setSlangDictionary(path): txt file with delimited words to be transformed into something else</li>
  </ul>

  <p><strong>Example:</strong></p>

  <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Normalizer">Normalizer</a> Scala docs for more details on the API.</p>

  <div class="tabs-box">

    <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">normalizer</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalized"</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>
</code></pre></div>    </div>

  </div>
</div>
<div class="h3-box">

  <h2 id="stemmer">Stemmer</h2>

  <p>Returns hard-stems out of words with the objective of retrieving the meaningful part of the word<br />
<strong>Output type:</strong> Token<br />
<strong>Input types:</strong> Token<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Stemmer.scala">Stemmer</a></p>

  <p><strong>Example:</strong></p>

  <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotator.package$$Stemmer$">Stemmer</a> Scala docs for more details on the API.</p>

  <div class="tabs-box">

    <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stemmer</span> <span class="o">=</span> <span class="n">Stemmer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"stem"</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">stemmer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Stemmer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>
</code></pre></div>    </div>

  </div>
</div>
<div class="h3-box">

  <h2 id="lemmatizer">Lemmatizer</h2>

  <p>Retrieves lemmas out of words with the objective of returning a base dictionary word<br />
<strong>Output type:</strong> Token<br />
<strong>Input types:</strong> Token<br />
<strong>Input:</strong> abduct -&gt; abducted abducting abduct abducts<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Lemmatizer.scala">Lemmatizer</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala">LemmatizerModel</a><br />
<strong>Functions:</strong></p>

  <ul>
    <li>setDictionary(path, keyDelimiter, valueDelimiter, readAs, options): Path and options to lemma dictionary, in lemma vs possible words format. readAs can be LINE_BY_LINE or SPARK_DATASET. options contain option passed to spark reader if readAs is SPARK_DATASET.</li>
  </ul>

  <p><strong>Example:</strong></p>

  <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Lemmatizer">Lemmatizer</a> Scala docs for more details on the API.</p>

  <div class="tabs-box">

    <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lemmatizer</span> <span class="o">=</span> <span class="n">Lemmatizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"lemma"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDictionary</span><span class="p">(</span><span class="s">"./lemmas001.txt"</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">lemmatizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Lemmatizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"lemma"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDictionary</span><span class="o">(</span><span class="s">"./lemmas001.txt"</span><span class="o">)</span>
</code></pre></div>    </div>

  </div>
</div>
<div class="h3-box">

  <h2 id="stopwordscleaner">StopWordsCleaner</h2>

  <p>This annotator excludes from a sequence of strings (e.g. the output of a <code class="language-plaintext highlighter-rouge">Tokenizer</code>, <code class="language-plaintext highlighter-rouge">Normalizer</code>, <code class="language-plaintext highlighter-rouge">Lemmatizer</code>, and <code class="language-plaintext highlighter-rouge">Stemmer</code>) and drops all the stop words from the input sequences.</p>

  <p><strong>Functions:</strong></p>

  <ul>
    <li><code class="language-plaintext highlighter-rouge">setStopWords</code>: The words to be filtered out. <code class="language-plaintext highlighter-rouge">Array[String]</code></li>
    <li><code class="language-plaintext highlighter-rouge">setCaseSensitive</code>: Whether to do a case sensitive comparison over the stop words.</li>
  </ul>

  <p><strong>Example:</strong></p>

  <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.StopWordsCleaner">StopWordsCleaner</a> Scala docs for more details on the API.</p>

  <div class="tabs-box">

    <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stop_words_cleaner</span> <span class="o">=</span> <span class="n">StopWordsCleaner</span><span class="p">()</span> \
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span> \
        <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
        <span class="p">.</span><span class="n">setStopWords</span><span class="p">([</span><span class="s">"this"</span><span class="p">,</span> <span class="s">"is"</span><span class="p">,</span> <span class="s">"and"</span><span class="p">])</span>
</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">stopWordsCleaner</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StopWordsCleaner</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setStopWords</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"this"</span><span class="o">,</span> <span class="s">"is"</span><span class="o">,</span> <span class="s">"and"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</code></pre></div>    </div>

    <p><strong>NOTE:</strong>
If you need to <code class="language-plaintext highlighter-rouge">setStopWords</code> from a text file, you can first read and convert it into an array of string:</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># your stop words text file, each line is one stop word
</span><span class="n">stopwords</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"/tmp/stopwords/english.txt"</span><span class="p">).</span><span class="n">collect</span><span class="p">()</span>
<span class="c1"># simply use it in StopWordsCleaner
</span><span class="n">stopWordsCleaner</span> <span class="o">=</span> <span class="n">new</span> <span class="n">StopWordsCleaner</span><span class="p">()</span>
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span>
      <span class="p">.</span><span class="n">setStopWords</span><span class="p">(</span><span class="n">stopwords</span><span class="p">)</span>
      <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="n">false</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// your stop words text file, each line is one stop word</span>
<span class="k">val</span> <span class="nv">stopwords</span> <span class="k">=</span> <span class="nv">sc</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="s">"/tmp/stopwords/english.txt"</span><span class="o">).</span><span class="py">collect</span><span class="o">()</span>
<span class="c1">// simply use it in StopWordsCleaner</span>
<span class="k">val</span> <span class="nv">stopWordsCleaner</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StopWordsCleaner</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setStopWords</span><span class="o">(</span><span class="n">stopwords</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</code></pre></div>    </div>

  </div>
</div>
<div class="h3-box">

  <h2 id="regexmatcher">RegexMatcher</h2>

  <p>Uses a reference file to match a set of regular expressions and put them inside a provided key. File must be comma separated.<br />
<strong>Output type:</strong> Regex<br />
<strong>Input types:</strong> Document<br />
<strong>Input:</strong> <code class="language-plaintext highlighter-rouge">the\\s\\w+</code>, “followed by ‘the’”<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/RegexMatcher.scala">RegexMatcher</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/RegexMatcherModel.scala">RegexMatcherModel</a><br />
<strong>Functions:</strong></p>

  <ul>
    <li>setStrategy(strategy): Can be any of <code class="language-plaintext highlighter-rouge">MATCH_FIRST|MATCH_ALL|MATCH_COMPLETE</code></li>
    <li>setRules(path, delimiter, readAs, options): Path to file containing a set of regex,key pair. readAs can be LINE_BY_LINE or SPARK_DATASET. options contain option passed to spark reader if readAs is SPARK_DATASET.</li>
  </ul>

  <p><strong>Example:</strong></p>

  <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.RegexMatcher">RegexMatcher</a> Scala docs for more details on the API.</p>

  <div class="tabs-box">

    <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">regex_matcher</span> <span class="o">=</span> <span class="n">RegexMatcher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStrategy</span><span class="p">(</span><span class="s">"MATCH_ALL"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"regex"</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">regexMatcher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RegexMatcher</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setStrategy</span><span class="o">(</span><span class="s">"MATCH_ALL"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"regex"</span><span class="o">)</span>
</code></pre></div>    </div>

  </div>
</div>
<div class="h3-box">

  <h2 id="textmatcher-phrase-matching">TextMatcher (Phrase matching)</h2>

  <p>Annotator to match entire phrases (by token) provided in a file against a Document<br />
<strong>Output type:</strong> Entity<br />
<strong>Input types:</strong> Document, Token<br />
<strong>Input:</strong> hello world, I am looking for you<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/TextMatcher.scala">TextMatcher</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/TextMatcherModel.scala">TextMatcherModel</a><br />
<strong>Functions:</strong></p>

  <ul>
    <li>setEntities(path, format, options): Provides a file with phrases to match. Default: Looks up path in configuration.</li>
    <li>path: a path to a file that contains the entities in the specified format.</li>
    <li>readAs: the format of the file, can be one of {ReadAs.LINE_BY_LINE, ReadAs.SPARK_DATASET}. Defaults to LINE_BY_LINE.</li>
    <li>options: a map of additional parameters. Defaults to {“format”: “text”}.</li>
  </ul>

  <p><strong>Example:</strong></p>

  <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.TextMatcher">TextMatcher</a> Scala docs for more details on the API.</p>

  <div class="tabs-box">

    <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">entity_extractor</span> <span class="o">=</span> <span class="n">TextMatcher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"inputCol"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEntities</span><span class="p">(</span><span class="s">"/path/to/file/myentities.txt"</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">entityExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TextMatcher</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"inputCol"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEntities</span><span class="o">(</span><span class="s">"/path/to/file/myentities.txt"</span><span class="o">)</span>
</code></pre></div>    </div>

  </div>
</div>
<div class="h3-box">

  <h2 id="chunker">Chunker</h2>

  <p>This annotator matches a pattern of part-of-speech tags in order to return meaningful phrases from document</p>

  <p><strong>Output type:</strong> Chunk<br />
<strong>Input types:</strong> Document, POS<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Chunker.scala">Chunker</a><br />
<strong>Functions:</strong></p>

  <ul>
    <li>setRegexParsers(patterns): A list of regex patterns to match chunks, for example: Array(“‹DT›?‹JJ›*‹NN›”)</li>
    <li>addRegexParser(patterns): adds a pattern to the current list of chunk patterns, for example: “‹DT›?‹JJ›*‹NN›”</li>
  </ul>

  <p><strong>Example:</strong></p>

  <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.Chunker">Chunker</a> Scala docs for more details on the API.</p>

  <div class="tabs-box">

    <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chunker</span> <span class="o">=</span> <span class="n">Chunker</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"‹NNP›+"</span><span class="p">,</span> <span class="s">"‹DT|PP</span><span class="se">\\</span><span class="s">$›?‹JJ›*‹NN›"</span><span class="p">])</span>
</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunker</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"‹NNP›+"</span><span class="o">,</span> <span class="s">"‹DT|PP\\$›?‹JJ›*‹NN›"</span><span class="o">))</span>
</code></pre></div>    </div>

  </div>
</div>
<div class="h3-box">

  <h2 id="ngramgenerator">NGramGenerator</h2>

  <p><code class="language-plaintext highlighter-rouge">NGramGenerator</code> annotator takes as input a sequence of strings (e.g. the output of a <code class="language-plaintext highlighter-rouge">Tokenizer</code>, <code class="language-plaintext highlighter-rouge">Normalizer</code>, <code class="language-plaintext highlighter-rouge">Stemmer</code>, <code class="language-plaintext highlighter-rouge">Lemmatizer</code>, and <code class="language-plaintext highlighter-rouge">StopWordsCleaner</code>). The parameter <code class="language-plaintext highlighter-rouge">n</code> is used to determine the number of terms in each n-gram. The output will consist of a sequence of n-grams where each n-gram is represented by a space-delimited string of n consecutive words with annotatorType <code class="language-plaintext highlighter-rouge">CHUNK</code> same as the <code class="language-plaintext highlighter-rouge">Chunker</code> annotator.</p>

  <p><strong>Output type:</strong> CHUNK<br />
<strong>Input types:</strong> TOKEN<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/NGramGenerator.scala">NGramGenerator</a><br />
<strong>Functions:</strong></p>

  <ul>
    <li>setN: number elements per n-gram (&gt;=1)</li>
    <li>setEnableCumulative: whether to calculate just the actual n-grams or all n-grams from 1 through n</li>
    <li>setDelimiter: Glue character used to join the tokens</li>
  </ul>

  <p><strong>Example:</strong></p>

  <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.NGramGenerator">NGramGenerator</a> Scala docs for more details on the API.</p>

  <div class="tabs-box">

    <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ngrams_cum</span> <span class="o">=</span> <span class="n">NGramGenerator</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngrams"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setN</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setEnableCumulative</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
            <span class="p">.</span><span class="n">setDelimiter</span><span class="p">(</span><span class="s">"_"</span><span class="p">)</span> <span class="c1"># Default is space
</span></code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">nGrams</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NGramGenerator</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setEnableCumulative</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setDelimiter</span><span class="o">(</span><span class="s">"_"</span><span class="o">)</span> <span class="c1">// Default is space</span>
</code></pre></div>    </div>

  </div>
</div>
<div class="h3-box">

  <h2 id="datematcher">DateMatcher</h2>

  <p>Reads from different forms of date and time expressions and converts them to a provided date format. Extracts only ONE date per sentence. Use with sentence detector for more matches.<br />
<strong>Output type:</strong> Date<br />
<strong>Input types:</strong> Document<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/DateMatcher.scala">DateMatcher</a><br />
<strong>Reads the following kind of dates:</strong></p>

  <ul>
    <li>1978-01-28</li>
    <li>1984/04/02</li>
    <li>1/02/1980</li>
    <li>2/28/79</li>
    <li>The 31st of April in the year 2008</li>
    <li>Fri, 21 Nov 1997</li>
    <li>Jan 21, ‘97</li>
    <li>Sun, Nov 21</li>
    <li>jan 1st</li>
    <li>next thursday</li>
    <li>last wednesday</li>
    <li>today</li>
    <li>tomorrow</li>
    <li>yesterday</li>
    <li>next week</li>
    <li>next month</li>
    <li>next year</li>
    <li>day after</li>
    <li>the day before</li>
    <li>0600h</li>
    <li>06:00 hours</li>
    <li>6pm</li>
    <li>5:30 a.m.</li>
    <li>at 5</li>
    <li>12:59</li>
    <li>23:59</li>
    <li>1988/11/23 6pm</li>
    <li>next week at 7.30</li>
    <li>5 am tomorrow</li>
  </ul>

  <p><strong>Functions:</strong></p>

  <ul>
    <li>setDateFormat(format): SimpleDateFormat standard date <em>output</em> formatting. Defaults to yyyy/MM/dd</li>
    <li>setAnchorDateYear: Add an anchor year for the relative dates such as a day after tomorrow. If not set it will use the current year. Example: 2021</li>
    <li>setAnchorDateMonth: Add an anchor month for the relative dates such as a day after tomorrow. If not set it will use the current month. Example: 1 which means January</li>
    <li>setAnchorDateDay: Add an anchor day of the day for the relative dates such as a day after tomorrow. If not set it will use the current day. Example: 11</li>
  </ul>

  <p><strong>Example:</strong></p>

  <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.DateMatcher">DateMatcher</a> Scala docs for more details on the API.</p>

  <div class="tabs-box">

    <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">date_matcher</span> <span class="o">=</span> <span class="n">DateMatcher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"date"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateFormat</span><span class="p">(</span><span class="s">"yyyy/MM/dd"</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">dateMatcher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DateMatcher</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"date"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setFormat</span><span class="o">(</span><span class="s">"yyyyMM"</span><span class="o">)</span>
</code></pre></div>    </div>

    <h2 id="multidatematcher">MultiDateMatcher</h2>

    <p>Reads from multiple different forms of date and time expressions and converts them to a provided date format. Extracts multiple dates per sentence.
<strong>Output type:</strong> Date<br />
<strong>Input types:</strong> Document<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/MultiDateMatcher.scala">MultiDateMatcher</a><br />
<strong>Reads the following kind of dates:</strong></p>

    <ul>
      <li>1978-01-28</li>
      <li>1984/04/02</li>
      <li>1/02/1980</li>
      <li>2/28/79</li>
      <li>The 31st of April in the year 2008</li>
      <li>Fri, 21 Nov 1997</li>
      <li>Jan 21, ‘97</li>
      <li>Sun, Nov 21</li>
      <li>jan 1st</li>
      <li>next thursday</li>
      <li>last wednesday</li>
      <li>today</li>
      <li>tomorrow</li>
      <li>yesterday</li>
      <li>next week</li>
      <li>next month</li>
      <li>next year</li>
      <li>day after</li>
      <li>the day before</li>
      <li>0600h</li>
      <li>06:00 hours</li>
      <li>6pm</li>
      <li>5:30 a.m.</li>
      <li>at 5</li>
      <li>12:59</li>
      <li>23:59</li>
      <li>1988/11/23 6pm</li>
      <li>next week at 7.30</li>
      <li>5 am tomorrow</li>
    </ul>

    <p><strong>Functions:</strong></p>

    <ul>
      <li>setDateFormat(format): SimpleDateFormat standard date <em>output</em> formatting. Defaults to yyyy/MM/dd</li>
      <li>setAnchorDateYear: Add an anchor year for the relative dates such as a day after tomorrow. If not set it will use the current year. Example: 2021</li>
      <li>setAnchorDateMonth: Add an anchor month for the relative dates such as a day after tomorrow. If not set it will use the current month. Example: 1 which means January</li>
      <li>setAnchorDateDay: Add an anchor day of the day for the relative dates such as a day after tomorrow. If not set it will use the current day. Example: 11</li>
    </ul>

    <p><strong>Example:</strong></p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.MultiDateMatcher">MultiDateMatcher</a> Scala docs for more details on the API.</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">date_matcher</span> <span class="o">=</span> <span class="n">MultiDateMatcher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"date"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateFormat</span><span class="p">(</span><span class="s">"yyyy/MM/dd"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">dateMatcher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiDateMatcher</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"date"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setFormat</span><span class="o">(</span><span class="s">"yyyyMM"</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>
  </div>
  <div class="h3-box">

    <h2 id="sentencedetector">SentenceDetector</h2>

    <p>Finds sentence bounds in raw text. Applies rules from Pragmatic Segmenter.<br />
<strong>Output type:</strong> Sentence
<strong>Input types:</strong> Document<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/SentenceDetector.scala">SentenceDetector</a><br />
<strong>Functions:</strong></p>

    <ul>
      <li>setCustomBounds(string): Custom sentence separator text</li>
      <li>setUseCustomOnly(bool): Use only custom bounds without considering those of Pragmatic Segmenter. Defaults to false. Needs customBounds.</li>
      <li>setUseAbbreviations(bool): Whether to consider abbreviation strategies for better accuracy but slower performance. Defaults to true.</li>
      <li>setExplodeSentences(bool): Whether to split sentences into different Dataset rows. Useful for higher parallelism in fat rows. Defaults to false.</li>
    </ul>

    <p><strong>Example:</strong></p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector">SentenceDetector</a> Scala docs for more details on the API.</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>
  </div>
  <div class="h3-box">

    <h2 id="postagger-part-of-speech-tagger">POSTagger (Part of speech tagger)</h2>

    <p>Sets a POS tag to each word within a sentence. Its train data (train_pos) is a spark dataset of <a href="#TrainPOS">POS format values</a> with Annotation columns.<br />
<strong>Output type:</strong> POS<br />
<strong>Input types:</strong> Document, Token<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproach.scala">PerceptronApproach</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala">PerceptronModel</a><br />
<strong>Functions:</strong></p>

    <ul>
      <li>setNIterations(number): Number of iterations for training. May improve accuracy but takes longer. Default 5.</li>
      <li>setPosColumn(colname): Column containing an array of POS Tags matching every token on the line.</li>
    </ul>

    <p><strong>Example:</strong></p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach">PerceptronApproach</a> Scala docs for more details on the API.</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">PerceptronApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setNIterations</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_pos</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PerceptronApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setNIterations</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
    <span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainPOS</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>
  </div>
  <div class="h3-box">

    <h2 id="viveknsentimentdetector">ViveknSentimentDetector</h2>

    <p>Scores a sentence for a sentiment</p>

    <p><strong>Output type:</strong> sentiment<br />
<strong>Input types:</strong> Document, Token<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentApproach.scala">ViveknSentimentApproach</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel.scala">ViveknSentimentModel</a><br />
<strong>Functions:</strong></p>

    <ul>
      <li>setSentimentCol(colname): Column with sentiment analysis row’s result for training. If not set, external sources need to be set instead.</li>
      <li>setSentimentCol(colname): column with the sentiment result of every row. Must be ‘positive’ or ‘negative’</li>
      <li>setCorpusPrune(true): when training on small data you may want to disable this to not cut off infrequent words</li>
    </ul>

    <p><strong>Input:</strong> File or folder of text files of positive and negative data<br />
<strong>Example:</strong></p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.sda.vivekn.ViveknSentimentApproach">ViveknSentimentApproach</a> Scala docs for more details on the API.</p>

    <p>Train your own model:</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sentiment_detector</span> <span class="o">=</span> <span class="n">ViveknSentimentApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentiment"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setSentimentCol</span><span class="p">(</span><span class="s">"sentiment_label"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">sentimentDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ViveknSentimentApproach</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"vivekn"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setSentimentCol</span><span class="o">(</span><span class="s">"sentiment_label"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setCorpusPrune</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>

    <p>Use a pretrained model:</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sentiment_detector</span> <span class="o">=</span> <span class="n">ViveknSentimentModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentiment"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">sentimentDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">ViveknSentimentModel</span><span class="o">.</span><span class="py">pretrained</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"vivekn"</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>
  </div>
  <div class="h3-box">

    <h2 id="sentimentdetector-sentiment-analysis">SentimentDetector (Sentiment analysis)</h2>

    <p>Scores a sentence for a sentiment<br />
<strong>Output type:</strong> sentiment</p>

    <p><strong>Input types:</strong> Document, Token</p>

    <p><strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetector.scala">SentimentDetector</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetectorModel.scala">SentimentDetectorModel</a><br />
<strong>Functions:</strong></p>

    <ul>
      <li>setDictionary(path, delimiter, readAs, options): path to file with list of inputs and their content, with such delimiter, readAs LINE_BY_LINE or as SPARK_DATASET. If latter is set, options is passed to spark reader.</li>
      <li>setPositiveMultiplier(double): Defaults to 1.0</li>
      <li>setNegativeMultiplier(double): Defaults to -1.0</li>
      <li>setIncrementMultiplier(double): Defaults to 2.0</li>
      <li>setDecrementMultiplier(double): Defaults to -2.0</li>
      <li>setReverseMultiplier(double): Defaults to -1.0</li>
    </ul>

    <p><strong>Input:</strong></p>

    <ul>
      <li>superb,positive</li>
      <li>bad,negative</li>
      <li>lack of,revert</li>
      <li>very,increment</li>
      <li>barely,decrement</li>
    </ul>

    <p><strong>Example:</strong></p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.sda.pragmatic.SentimentDetector">SentimentDetector</a> Scala docs for more details on the API.</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sentiment_detector</span> <span class="o">=</span> <span class="n">SentimentDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentiment"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">sentimentDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentimentDetector</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentiment"</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>
  </div>
  <div class="h3-box">

    <h2 id="wordembeddings">WordEmbeddings</h2>

    <p>Word Embeddings lookup annotator that maps tokens to vectors</p>

    <p><strong>Output type:</strong> Word_Embeddings</p>

    <p><strong>Input types:</strong> Document, Token</p>

    <p><strong>Reference:</strong>  <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddings.scala">WordEmbeddings</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel.scala">WordEmbeddingsModel</a><br />
<strong>Functions:</strong></p>

    <ul>
      <li>setStoragePath(path, format): sets <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> options.
        <ul>
          <li>path: word embeddings file</li>
          <li>format: format of word embeddings files:
            <ul>
              <li>TEXT -&gt; This format is usually used by <a href="https://nlp.stanford.edu/projects/glove/">Glove</a></li>
              <li>BINARY -&gt; This format is usually used by <a href="https://code.google.com/archive/p/word2vec/">Word2Vec</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li>setCaseSensitive: whether to ignore case in tokens for embeddings matching</li>
    </ul>

    <p><strong>Example:</strong></p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.WordEmbeddings">WordEmbeddings</a> Scala docs for more details on the API.</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddings</span><span class="p">()</span>
      <span class="p">.</span><span class="n">setStoragePath</span><span class="p">(</span><span class="s">"/tmp/glove.6B.100d.txt"</span><span class="p">,</span> <span class="s">"TEXT"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setDimension</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setStorageRef</span><span class="p">(</span><span class="s">"glove_100d"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">WordEmbeddings</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setStoragePath</span><span class="o">(</span><span class="s">"/tmp/glove.6B.100d.txt"</span><span class="o">,</span> <span class="s">"TEXT)
      .setDimension(100)
      .setStorageRef("</span><span class="n">glove_100d</span><span class="s">") // Use or save this WordEmbeddings with storageRef
      .setInputCols("</span><span class="n">document</span><span class="s">", "</span><span class="n">token</span><span class="s">")
      .setOutputCol("</span><span class="n">embeddings</span><span class="err">"</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>

    <p>There are also two convenient functions to retrieve the embeddings coverage with respect to the transformed dataset:</p>

    <ul>
      <li>withCoverageColumn(dataset, embeddingsCol, outputCol): Adds a custom column with <strong>word coverage</strong> stats for the embedded field: (coveredWords, totalWords, coveragePercentage). This creates a new column with statistics for each row.</li>
      <li>overallCoverage(dataset, embeddingsCol): Calculates overall <strong>word coverage</strong> for the whole data in the embedded field. This returns a single coverage object considering all rows in the field.</li>
    </ul>

  </div>
  <div class="h3-box">

    <h2 id="bertembeddings">BertEmbeddings</h2>

    <p>BERT (Bidirectional Encoder Representations from Transformers) provides dense vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture</p>

    <p>You can find the pre-trained models for <code class="language-plaintext highlighter-rouge">BertEmbeddings</code> in the <a href="https://github.com/JohnSnowLabs/spark-nlp-models">Spark NLP Models</a> repository</p>

    <p><strong>Output type:</strong> Word_Embeddings</p>

    <p><strong>Input types:</strong> Document, Token</p>

    <p><strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala">BertEmbeddings</a></p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertEmbeddings">BertEmbeddings</a> Scala docs for more</p>

    <p>How to use pretrained BertEmbeddings:</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">bert</span> <span class="o">=</span> <span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">bert</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert"</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>
    <div class="h3-box">

      <h2 id="bertsentenceembeddings">BertSentenceEmbeddings</h2>

      <p>BERT (Bidirectional Encoder Representations from Transformers) provides dense vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture</p>

      <p>You can find the pre-trained models for <code class="language-plaintext highlighter-rouge">BertEmbeddings</code> in the <a href="https://github.com/JohnSnowLabs/spark-nlp-models">Spark NLP Models</a> repository</p>

      <p><strong>Output type:</strong> Sentence_Embeddings</p>

      <p><strong>Input types:</strong> Document</p>

      <p><strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala">BertSentenceEmbeddings</a></p>

      <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings">BertSentenceEmbeddings</a> Scala docs for more</p>

      <p>How to use pretrained BertEmbeddings:</p>

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">bert</span> <span class="o">=</span> <span class="n">BertSentencembeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_sentence_embeddings"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">bert</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert_sentence_embeddings"</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>
  </div>
  <div class="h3-box">

    <h2 id="elmoembeddings">ElmoEmbeddings</h2>

    <p>Computes contextualized word representations using character-based word representations and bidirectional LSTMs</p>

    <p>You can find the pre-trained model for <code class="language-plaintext highlighter-rouge">ElmoEmbeddings</code> in the  <a href="https://github.com/JohnSnowLabs/spark-nlp-models#english---models">Spark NLP Models</a> repository</p>

    <p><strong>Output type:</strong> Word_Embeddings</p>

    <p><strong>Input types:</strong> Document, Token</p>

    <p><strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings.scala">ElmoEmbeddings</a></p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.ElmoEmbeddings">ElmoEmbeddings</a> Scala docs for more</p>

    <p>How to use pretrained ElmoEmbeddings:</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Online - Download the pretrained model
</span><span class="n">elmo</span> <span class="o">=</span> <span class="n">ElmoEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"elmo"</span><span class="p">)</span>

<span class="c1"># Offline - Download the pretrained model manually and extract it
</span><span class="n">elmo</span> <span class="o">=</span> <span class="n">ElmoEmbeddings</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"/elmo_en_2.4.0_2.4_1580488815299"</span><span class="p">)</span> \
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"elmo"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">val</span> <span class="nv">elmo</span> <span class="k">=</span> <span class="nv">ElmoEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"elmo"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setPoolingLayer</span><span class="o">(</span><span class="s">"elmo"</span><span class="o">)</span> <span class="c1">//  word_emb, lstm_outputs1, lstm_outputs2 or elmo</span>
</code></pre></div>      </div>

    </div>
  </div>
  <div class="h3-box">

    <h2 id="albertembeddings">AlbertEmbeddings</h2>

    <p>Computes contextualized word representations using “A Lite” implementation of BERT algorithm by applying parameter-reduction techniques</p>

    <p>You can find the pre-trained model for <code class="language-plaintext highlighter-rouge">AlbertEmbeddings</code> in the  <a href="https://github.com/JohnSnowLabs/spark-nlp-models#english---models">Spark NLP Models</a> repository</p>

    <p><strong>Functions:</strong></p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">setBatchSize(int)</code>: Batch size. Large values allows faster processing but requires more memory.</li>
      <li><code class="language-plaintext highlighter-rouge">setMaxSentenceLength(int)</code>: Max sentence length to process</li>
    </ul>

    <p><strong>Output type:</strong> Word_Embeddings</p>

    <p><strong>Input types:</strong> Document, Token</p>

    <p><strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.scala">AlbertEmbeddings</a></p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.AlbertEmbeddings">AlbertEmbeddings</a> Scala docs for more</p>

    <p>How to use pretrained AlbertEmbeddings:</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Online - Download the pretrained model
</span><span class="n">albert</span> <span class="o">=</span> <span class="n">AlbertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"albert"</span><span class="p">)</span>

<span class="c1"># Offline - Download the pretrained model manually and extract it
</span><span class="n">albert</span> <span class="o">=</span> <span class="n">AlbertEmbeddings</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"/albert_base_uncased_en_2.5.0_2.4_1588073363475"</span><span class="p">)</span> \
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"albert"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">val</span> <span class="nv">albert</span> <span class="k">=</span> <span class="nv">AlbertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"albert"</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>
  </div>
  <div class="h3-box">

    <h2 id="xlnetembeddings">XlnetEmbeddings</h2>

    <p>Computes contextualized word representations using combination of Autoregressive Language Model and Permutation Language Model</p>

    <p>You can find the pre-trained model for <code class="language-plaintext highlighter-rouge">XlnetEmbeddings</code> in the  <a href="https://github.com/JohnSnowLabs/spark-nlp-models#english---models">Spark NLP Models</a> repository</p>

    <p><strong>Functions:</strong></p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">setBatchSize(int)</code>: Batch size. Large values allows faster processing but requires more memory.</li>
      <li><code class="language-plaintext highlighter-rouge">setMaxSentenceLength(int)</code>: Max sentence length to process.</li>
    </ul>

    <p><strong>Output type:</strong> Word_Embeddings</p>

    <p><strong>Input types:</strong> Document, Token</p>

    <p><strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings.scala">XlnetEmbeddings</a></p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.XlnetEmbeddings">XlnetEmbeddings</a> Scala docs for more</p>

    <p>How to use pretrained XlnetEmbeddings:</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Online - Download the pretrained model
</span><span class="n">xlnet</span> <span class="o">=</span> <span class="n">XlnetEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"xlnet"</span><span class="p">)</span>

<span class="c1"># Offline - Download the pretrained model manually and extract it
</span><span class="n">xlnet</span> <span class="o">=</span> <span class="n">XlnetEmbeddings</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"/xlnet_large_cased_en_2.5.0_2.4_1588074397954"</span><span class="p">)</span> \
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"xlnet"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">val</span> <span class="nv">xlnet</span> <span class="k">=</span> <span class="nv">XlnetEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"xlnet"</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>
  </div>
  <div class="h3-box">

    <h2 id="universalsentenceencoder">UniversalSentenceEncoder</h2>

    <p>The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.</p>

    <p><strong>Output type:</strong> SENTENCE_EMBEDDINGS</p>

    <p><strong>Input types:</strong> Document</p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder">UniversalSentenceEncoder</a> Scala docs for more</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">use</span> <span class="o">=</span> <span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"use_embeddings"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">use</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">UniversalSentenceEncoder</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"use_embeddings"</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>
  </div>
  <div class="h3-box">

    <h2 id="sentenceembeddings">SentenceEmbeddings</h2>

    <p>This annotator converts the results from <code class="language-plaintext highlighter-rouge">WordEmbeddings</code>, <code class="language-plaintext highlighter-rouge">BertEmbeddings</code>, <code class="language-plaintext highlighter-rouge">ElmoEmbeddings</code>, <code class="language-plaintext highlighter-rouge">AlbertEmbeddings</code>, or <code class="language-plaintext highlighter-rouge">XlnetEmbeddings</code> into <code class="language-plaintext highlighter-rouge">sentence</code> or <code class="language-plaintext highlighter-rouge">document</code> embeddings by either summing up or averaging all the word embeddings in a sentence or a document (depending on the <code class="language-plaintext highlighter-rouge">inputCols</code>).</p>

    <p><strong>Functions:</strong></p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">setPoolingStrategy</code>: Choose how you would like to aggregate Word Embeddings to Sentence Embeddings: AVERAGE or SUM</li>
    </ul>

    <p><strong>Output type:</strong> SENTENCE_EMBEDDINGS</p>

    <p><strong>Input types:</strong> Document</p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.SentenceEmbeddings">SentenceEmbeddings</a> Scala docs for more</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">SentenceEmbeddings</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"AVERAGE"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">embeddingsSentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceEmbeddings</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setPoolingStrategy</span><span class="o">(</span><span class="s">"AVERAGE"</span><span class="o">)</span>
</code></pre></div>      </div>

      <p><strong>NOTE:</strong></p>

      <p>If you choose <code class="language-plaintext highlighter-rouge">document</code> as your input for <code class="language-plaintext highlighter-rouge">Tokenizer</code>, <code class="language-plaintext highlighter-rouge">WordEmbeddings/BertEmbeddings</code>, and <code class="language-plaintext highlighter-rouge">SentenceEmbeddings</code> then it averages/sums all the embeddings into one array of embeddings. However, if you choose <code class="language-plaintext highlighter-rouge">sentence</code> as <code class="language-plaintext highlighter-rouge">inputCols</code> then for each sentence <code class="language-plaintext highlighter-rouge">SentenceEmbeddings</code> generates one array of embeddings.</p>

      <p><strong>TIP:</strong></p>

      <p>How to explode and convert these embeddings into <code class="language-plaintext highlighter-rouge">Vectors</code> or what’s known as <code class="language-plaintext highlighter-rouge">Feature</code> column so it can be used in Spark ML regression or clustering functions:</p>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">org.apache.spark.ml.linal</span> <span class="kn">import</span> <span class="n">Vector</span><span class="p">,</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">udf</span>
<span class="c1"># Let's create a UDF to take array of embeddings and output Vectors
</span><span class="o">@</span><span class="n">udf</span><span class="p">(</span><span class="n">Vector</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">convertToVectorUDF</span><span class="p">(</span><span class="n">matrix</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">Vectors</span><span class="p">.</span><span class="n">dense</span><span class="p">(</span><span class="n">matrix</span><span class="p">.</span><span class="n">toArray</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">_</span><span class="p">.</span><span class="n">toDouble</span><span class="p">))</span>


<span class="c1"># Now let's explode the sentence_embeddings column and have a new feature column for Spark ML
</span><span class="n">pipelineDF</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">explode</span><span class="p">(</span><span class="s">"sentence_embeddings.embeddings"</span><span class="p">).</span><span class="k">as</span><span class="p">(</span><span class="s">"sentence_embedding"</span><span class="p">))</span>
<span class="p">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">"features"</span><span class="p">,</span> <span class="n">convertToVectorUDF</span><span class="p">(</span><span class="s">"sentence_embedding"</span><span class="p">))</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.</span><span class="o">{</span><span class="nc">Vector</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">}</span>

<span class="c1">// Let's create a UDF to take array of embeddings and output Vectors</span>
<span class="k">val</span> <span class="nv">convertToVectorUDF</span> <span class="k">=</span> <span class="nf">udf</span><span class="o">((</span><span class="n">matrix</span> <span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">Float</span><span class="o">])</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="nv">Vectors</span><span class="o">.</span><span class="py">dense</span><span class="o">(</span><span class="nv">matrix</span><span class="o">.</span><span class="py">toArray</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="nv">_</span><span class="o">.</span><span class="py">toDouble</span><span class="o">))</span>
<span class="o">})</span>

<span class="c1">// Now let's explode the sentence_embeddings column and have a new feature column for Spark ML</span>
<span class="nv">pipelineDF</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="nf">explode</span><span class="o">(</span><span class="n">$</span><span class="s">"sentence_embeddings.embeddings"</span><span class="o">).</span><span class="py">as</span><span class="o">(</span><span class="s">"sentence_embedding"</span><span class="o">))</span>
<span class="o">.</span><span class="py">withColumn</span><span class="o">(</span><span class="s">"features"</span><span class="o">,</span> <span class="nf">convertToVectorUDF</span><span class="o">(</span><span class="n">$</span><span class="s">"sentence_embedding"</span><span class="o">))</span>
</code></pre></div>      </div>

    </div>
  </div>
  <div class="h3-box">

    <h2 id="chunkembeddings">ChunkEmbeddings</h2>

    <p>This annotator utilizes <code class="language-plaintext highlighter-rouge">WordEmbeddings</code> or <code class="language-plaintext highlighter-rouge">BertEmbeddings</code> to generate chunk embeddings from either <code class="language-plaintext highlighter-rouge">Chunker</code>, <code class="language-plaintext highlighter-rouge">NGramGenerator</code>, or <code class="language-plaintext highlighter-rouge">NerConverter</code> outputs.</p>

    <p><strong>Functions:</strong></p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">setPoolingStrategy</code>: Choose how you would like to aggregate Word Embeddings to Sentence Embeddings: AVERAGE or SUM</li>
    </ul>

    <p><strong>Output type:</strong> CHUNK</p>

    <p><strong>Input types:</strong> CHUNK, Word_Embeddings</p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.embeddings.ChunkEmbeddings">ChunkEmbeddings</a> Scala docs for more</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chunk_embeddings</span> <span class="o">=</span> <span class="n">ChunkEmbeddings</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk_embeddings"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"AVERAGE"</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">chunkSentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkEmbeddings</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk_embeddings"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setPoolingStrategy</span><span class="o">(</span><span class="s">"AVERAGE"</span><span class="o">)</span>
</code></pre></div>      </div>

      <p><strong>TIP:</strong></p>

      <p>How to explode and convert these embeddings into <code class="language-plaintext highlighter-rouge">Vectors</code> or what’s known as <code class="language-plaintext highlighter-rouge">Feature</code> column so it can be used in Spark ML regression or clustering functions:</p>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">org.apache.spark.ml.linal</span> <span class="kn">import</span> <span class="n">Vector</span><span class="p">,</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">udf</span>

<span class="o">//</span> <span class="n">Let</span><span class="s">'s create a UDF to take array of embeddings and output Vectors
@udf(Vector)
def convertToVectorUDF(matrix):
    return Vectors.dense(matrix.toArray.map(_.toDouble))

</span></code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.</span><span class="o">{</span><span class="nc">Vector</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">}</span>

<span class="c1">// Let's create a UDF to take array of embeddings and output Vectors</span>
<span class="k">val</span> <span class="nv">convertToVectorUDF</span> <span class="k">=</span> <span class="nf">udf</span><span class="o">((</span><span class="n">matrix</span> <span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">Float</span><span class="o">])</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="nv">Vectors</span><span class="o">.</span><span class="py">dense</span><span class="o">(</span><span class="nv">matrix</span><span class="o">.</span><span class="py">toArray</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="nv">_</span><span class="o">.</span><span class="py">toDouble</span><span class="o">))</span>
<span class="o">})</span>

<span class="c1">// Now let's explode the sentence_embeddings column and have a new feature column for Spark ML</span>
<span class="nv">pipelineDF</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="nf">explode</span><span class="o">(</span><span class="n">$</span><span class="s">"chunk_embeddings.embeddings"</span><span class="o">).</span><span class="py">as</span><span class="o">(</span><span class="s">"chunk_embeddings_exploded"</span><span class="o">))</span>
<span class="o">.</span><span class="py">withColumn</span><span class="o">(</span><span class="s">"features"</span><span class="o">,</span> <span class="nf">convertToVectorUDF</span><span class="o">(</span><span class="n">$</span><span class="s">"chunk_embeddings_exploded"</span><span class="o">))</span>
</code></pre></div>      </div>

    </div>
  </div>
  <div class="h3-box">

    <h2 id="classifierdl-multi-class-text-classification">ClassifierDL (Multi-class Text Classification)</h2>

    <p>ClassifierDL is a generic Multi-class Text Classification. ClassifierDL uses the state-of-the-art Universal Sentence Encoder as an input for text classifications. The ClassifierDL annotator uses a deep learning model (DNNs) we have built inside TensorFlow and supports up to 100 classes</p>

    <p><strong>NOTE</strong>: This annotator accepts a label column of a single item in either type of String, Int, Float, or Double.</p>

    <p><strong>NOTE</strong>: UniversalSentenceEncoder, BertSentenceEmbeddings, or SentenceEmbeddings can be used for the inputCol</p>

    <p><strong>Output type:</strong> CATEGORY</p>

    <p><strong>Input types:</strong> SENTENCE_EMBEDDINGS</p>

    <p><strong>Functions:</strong></p>

    <ul>
      <li>setLabelColumn: If DatasetPath is not provided, this Seq[Annotation] type of column should have labeled data per token.</li>
      <li>setLr: Initial learning rate.</li>
      <li>setBatchSize: Batch size for training.</li>
      <li>setDropout: Dropout coefficient.</li>
      <li>setMaxEpochs: Maximum number of epochs to train.</li>
      <li>setEnableOutputLogs: Whether to output to annotators log folder.</li>
      <li>setValidationSplit: Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off.</li>
      <li>setVerbose: Level of verbosity during training.</li>
      <li>setOutputLogsPath: Folder path to save training logs.</li>
    </ul>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLApproach">ClassifierDLApproach</a> Scala docs for more</p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLModel">ClassifierDLModel</a> Scala docs for more</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">docClassifier</span> <span class="o">=</span> <span class="n">ClassifierDLApproach</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setLr</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">docClassifier</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ClassifierDLApproach</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">64</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">20</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mi">5</span><span class="n">e</span><span class="o">-</span><span class="mf">3f</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.5f</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>

    <p>Please refer to <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/jupyter/training/english/classification">existing notebooks</a> for more examples.</p>

  </div>
  <div class="h3-box">

    <h2 id="multiclassifierdl-multi-label-text-classification">MultiClassifierDL (Multi-label Text Classification)</h2>

    <p>MultiClassifierDL is a Multi-label Text Classification. MultiClassifierDL uses a Bidirectional GRU with Convolution model that we have built inside TensorFlow and supports up to 100 classes. The input to MultiClassifierDL is Sentence Embeddings such as state-of-the-art UniversalSentenceEncoder, BertSentenceEmbeddings, or SentenceEmbeddings</p>

    <p><strong>NOTE</strong>: This annotator accepts a label column of a single item in either type of String, Int, Float, or Double.</p>

    <p><strong>NOTE</strong>: UniversalSentenceEncoder, BertSentenceEmbeddings, or SentenceEmbeddings can be used for the inputCol</p>

    <p><strong>Output type:</strong> CATEGORY</p>

    <p><strong>Input types:</strong> SENTENCE_EMBEDDINGS</p>

    <p><strong>Functions:</strong></p>

    <ul>
      <li>setLabelColumn: If DatasetPath is not provided, this Seq[Annotation] type of column should have labeled data per token.</li>
      <li>setLr: Initial learning rate.</li>
      <li>setBatchSize: Batch size for training.</li>
      <li>setMaxEpochs: Maximum number of epochs to train.</li>
      <li>setEnableOutputLogs: Whether to output to annotators log folder.</li>
      <li>setValidationSplit: Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off.</li>
      <li>setVerbose: Level of verbosity during training.</li>
      <li>setOutputLogsPath: Folder path to save training logs.</li>
    </ul>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.MultiClassifierDLApproach">MultiClassifierDLApproach</a> Scala docs for more</p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.MultiClassifierDLModel">MultiClassifierDLModel</a> Scala docs for more</p>

    <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">docMultiClassifier</span> <span class="o">=</span> <span class="n">MultiClassifierDLApproach</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setLr</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">docMultiClassifier</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiClassifierDLApproach</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">64</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">20</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mi">5</span><span class="n">e</span><span class="o">-</span><span class="mf">3f</span><span class="o">)</span>
</code></pre></div>    </div>

    <p>Please refer to <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/jupyter/training/english/classification">existing notebooks</a> for more examples.</p>

  </div>
  <div class="h3-box">

    <h2 id="sentimentdl-multi-class-sentiment-analysis-annotator">SentimentDL (Multi-class Sentiment Analysis annotator)</h2>

    <p>SentimentDL is an annotator for multi-class sentiment analysis. This annotator comes with 2 available pre-trained models trained on IMDB and Twitter datasets</p>

    <p><strong>NOTE</strong>: This annotator accepts a label column of a single item in either type of String, Int, Float, or Double.</p>

    <p><strong>NOTE</strong>: UniversalSentenceEncoder, BertSentenceEmbeddings, or SentenceEmbeddings can be used for the inputCol</p>

    <p><strong>Output type:</strong> CATEGORY</p>

    <p><strong>Input types:</strong> SENTENCE_EMBEDDINGS</p>

    <p><strong>Functions:</strong></p>

    <ul>
      <li>setLabelColumn: If DatasetPath is not provided, this Seq[Annotation] type of column should have labeled data per token.</li>
      <li>setLr: Initial learning rate.</li>
      <li>setBatchSize: Batch size for training.</li>
      <li>setDropout: Dropout coefficient.</li>
      <li>setThreshold: The minimum threshold for the final result otheriwse it will be either neutral or the value set in thresholdLabel.</li>
      <li>setThresholdLabel: In case the score is less than threshold, what should be the label. Default is neutral.</li>
      <li>setMaxEpochs: Maximum number of epochs to train.</li>
      <li>setEnableOutputLogs: Whether to output to annotators log folder.</li>
      <li>setOutputLogsPath: Folder path to save training logs.</li>
      <li>setValidationSplit: Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off.</li>
      <li>setVerbose: Level of verbosity during training.</li>
    </ul>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.SentimentDLApproach">SentimentDLApproach</a> Scala docs for more</p>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.classifier.dl.SentimentDLModel">SentimentDLModel</a> Scala docs for more</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sentimentClassifier</span> <span class="o">=</span> <span class="n">SentimentDLApproach</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setLr</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">sentimentClassifier</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentimentDLApproach</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">64</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">20</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mi">5</span><span class="n">e</span><span class="o">-</span><span class="mf">3f</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.5f</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>

    <p>Please refer to <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/classification/">existing notebooks</a> for more examples.</p>

  </div>
  <div class="h3-box">

    <h2 id="languagedetectordl-language-detection-and-identiffication">LanguageDetectorDL (Language Detection and Identiffication)</h2>

    <p>LanguageDetectorDL is a state-of-the-art language detection and identification annotator trained by using TensorFlow/keras neural networks.</p>

    <p><strong>Output type:</strong> LANGUAGE</p>

    <p><strong>Input types:</strong> DOCUMENT or SENTENCE</p>

    <p><strong>Functions:</strong></p>

    <ul>
      <li>setThreshold: The minimum threshold for the final result otheriwse it will be either neutral or the value set in thresholdLabel.</li>
      <li>setThresholdLabel: In case the score is less than threshold, what should be the label. Default is Unknown.</li>
      <li>setCoalesceSentences: If sets to true the output of all sentences will be averaged to one output instead of one output per sentence. Default to true.</li>
    </ul>

    <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ld.dl.LanguageDetectorDL">LanguageDetectorDL</a> Scala docs for more</p>

    <div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">languageDetector</span> <span class="o">=</span> <span class="n">LanguageDetectorDL</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ld_wiki_20"</span><span class="p">)</span>
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"language"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setCoalesceSentences</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">val</span> <span class="nv">languageDetector</span> <span class="k">=</span> <span class="nv">LanguageDetectorDL</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ld_wiki_20"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"language"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setThreshold</span><span class="o">(</span><span class="mf">0.3f</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setCoalesceSentences</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>
    <div class="h3-box">

      <h2 id="yakemodel-keywords-extraction">YakeModel (Keywords Extraction)</h2>

      <p>Yake is an Unsupervised, Corpus-Independent, Domain and Language-Independent and Single-Document keyword extraction algorithm.</p>

      <p>sExtracting keywords from texts has become a challenge for individuals and organizations as the information grows in complexity and size. The need to automate this task so that text can be processed in a timely and adequate manner has led to the emergence of automatic keyword extraction tools. Yake is a novel feature-based system for multi-lingual keyword extraction, which supports texts of different sizes, domain or languages. Unlike other approaches, Yake does not rely on dictionaries nor thesauri, neither is trained against any corpora. Instead, it follows an unsupervised approach which builds upon features extracted from the text, making it thus applicable to documents written in different languages without the need for further knowledge. This can be beneficial for a large number of tasks and a plethora of situations where access to training corpora is either limited or restricted.</p>

      <p>The algorithm makes use of the position of a sentence and token. Therefore, to use the annotator, the text should be first sent through a Sentence Boundary Detector and then a tokenizer.</p>

      <p>You can tweak the following parameters to get the best result from the annotator.</p>

      <p><strong>Output type:</strong> KEYWORD</p>

      <p><strong>Input types:</strong> TOKEN</p>

      <p><strong>Functions:</strong></p>

      <ul>
        <li>setMinNGrams(int) Select the minimum length of a extracted keyword</li>
        <li>setMaxNGrams(int) Select the maximum length of a extracted keyword</li>
        <li>setNKeywords(int) Extract the top N keywords</li>
        <li>setStopWords(list) Set the list of stop words</li>
        <li>setThreshold(float) Each keyword will be given a keyword score greater than 0. (Lower the score better the keyword) Set an upper bound for the keyword score from this method.</li>
        <li>setWindowSize(int) Yake will construct a co-occurence matrix. You can set the window size for the cooccurence matrix construction from this method. ex: windowSize=2 will look at two words to both left and right of a candidate word.</li>
      </ul>

      <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.keyword.yake.YakeModel">YakeModel</a> Scala docs for more</p>

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">keywords</span> <span class="o">=</span> <span class="n">YakeModel</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"keywords"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMinNGrams</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxNGrams</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setNKeywords</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStopWords</span><span class="p">(</span><span class="n">stopwords</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">val</span> <span class="nv">keywords</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">YakeModel</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"keywords"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMinNGrams</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMaxNGrams</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setNKeywords</span><span class="o">(</span><span class="mi">20</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setStopWords</span><span class="o">(</span><span class="n">stopwords</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>
    <div class="h3-box">

      <h2 id="ner-crf-named-entity-recognition-crf-annotator">NER CRF (Named Entity Recognition CRF annotator)</h2>

      <p>This Named Entity recognition annotator allows for a generic model to be trained by utilizing a CRF machine learning algorithm. Its train data (train_ner) is either a labeled or an <a href="#conll-dataset">external CoNLL 2003 IOB based</a> spark dataset with Annotations columns. Also the user has to provide <a href="#WordEmbeddings">word embeddings annotation</a> column.<br />
Optionally the user can provide an entity dictionary file for better accuracy<br />
<strong>Output type:</strong> Named_Entity<br />
<strong>Input types:</strong> Document, Token, POS, Word_Embeddings<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfApproach.scala">NerCrfApproach</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfModel.scala">NerCrfModel</a><br />
<strong>Functions:</strong></p>

      <ul>
        <li>setLabelColumn: If DatasetPath is not provided, this Seq[Annotation] type of column should have labeled data per token</li>
        <li>setMinEpochs: Minimum number of epochs to train</li>
        <li>setMaxEpochs: Maximum number of epochs to train</li>
        <li>setL2: L2 regularization coefficient for CRF</li>
        <li>setC0: c0 defines decay speed for gradient</li>
        <li>setLossEps: If epoch relative improvement lass than this value, training is stopped</li>
        <li>setMinW: Features with less weights than this value will be filtered out</li>
        <li>setExternalFeatures(path, delimiter, readAs, options): Path to file or folder of line separated file that has something like this: Volvo:ORG with such delimiter, readAs LINE_BY_LINE or SPARK_DATASET with options passed to the latter.</li>
        <li>setEntities: Array of entities to recognize</li>
        <li>setVerbose: Verbosity level</li>
        <li>setRandomSeed: Random seed</li>
      </ul>

      <p><strong>Example:</strong></p>

      <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.crf.NerCrfApproach">NerCrfApproach</a> Scala docs for more details on the API.</p>

      <div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerCrfApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMinEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setLossEps</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDicts</span><span class="p">([</span><span class="s">"ner-corpus/dict.txt"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setL2</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setC0</span><span class="p">(</span><span class="mi">1250000</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRandomSeed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_ner</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerCrfApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMinEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setC0</span><span class="o">(</span><span class="mi">34</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setL2</span><span class="o">(</span><span class="mf">3.0</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainNer</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>
    </div>
    <div class="h3-box">

      <h2 id="ner-dl-named-entity-recognition-deep-learning-annotator">NER DL (Named Entity Recognition Deep Learning annotator)</h2>

      <p>This Named Entity recognition annotator allows to train generic NER model based on Neural Networks. Its train data (train_ner) is either a labeled or an <a href="#conll-dataset">external CoNLL 2003 IOB based</a> spark dataset with Annotations columns. Also the user has to provide <a href="#WordEmbeddings">word embeddings annotation</a> column.<br />
Neural Network architecture is Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets.<br />
<strong>Output type:</strong> Named_Entity  <br />
<strong>Input types:</strong> Document, Token, Word_Embeddings  <br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLApproach.scala">NerDLApproach</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala">NerDLModel</a><br />
<strong>Functions:</strong></p>

      <ul>
        <li>setLabelColumn: If DatasetPath is not provided, this Seq[Annotation] type of column should have labeled data per token.</li>
        <li>setMaxEpochs: Maximum number of epochs to train.</li>
        <li>setLr: Initial learning rate.</li>
        <li>setPo: Learning rate decay coefficient. Real Learning Rate: lr / (1 + po * epoch).</li>
        <li>setBatchSize: Batch size for training.</li>
        <li>setDropout: Dropout coefficient.</li>
        <li>setVerbose: Verbosity level.</li>
        <li>setRandomSeed: Random seed.</li>
        <li>setOutputLogsPath: Folder path to save training logs.</li>
      </ul>

      <p><strong>Note:</strong> Please check <a href="graph.md">here</a> in case you get an <strong>IllegalArgumentException</strong> error with a description such as:
<em>Graph [parameter] should be [value]: Could not find a suitable tensorflow graph for embeddings dim: [value] tags: [value] nChars: [value]. Generate graph by python code in python/tensorflow/ner/create_models before usage and use setGraphFolder Param to point to output.</em></p>

      <p><strong>Example:</strong></p>

      <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.dl.NerDLApproach">NerDLApproach</a> Scala docs for more details on the API.</p>

      <div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRandomSeed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_ner</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDLApproach</span><span class="o">()</span>
        <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">120</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setPo</span><span class="o">(</span><span class="mf">0.03f</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mf">0.2f</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.5f</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">9</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="nv">Verbose</span><span class="o">.</span><span class="py">Epochs</span><span class="o">)</span>
        <span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainNer</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>
    </div>
    <div class="h3-box">

      <h2 id="ner-converter-converts-iob-or-iob2-representation-of-ner-to-user-friendly">NER Converter (Converts IOB or IOB2 representation of NER to user-friendly)</h2>

      <p>NER Converter used to finalize work of NER annotators. Combines entites with types <code class="language-plaintext highlighter-rouge">B-</code>, <code class="language-plaintext highlighter-rouge">I-</code> and etc. to the Chunks with Named entity in the metadata field (if LightPipeline is used can be extracted after <code class="language-plaintext highlighter-rouge">fullAnnotate()</code>)</p>

      <p>This NER converter can be used to the output of a NER model into the ner chunk format.</p>

      <p><strong>Output type:</strong> Chunk
<strong>Input types:</strong> Document, Token, Named_Entity
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/NerConverter.scala">NerConverter</a>
<strong>Functions:</strong></p>

      <ul>
        <li>setWhiteList(Array(String)): If defined, list of entities to process. The rest will be ignored. Do not include IOB prefix on labels.</li>
        <li>setPreservePosition(Boolean): Whether to preserve the original position of the tokens in the original document or use the modified tokens.</li>
      </ul>

      <p><strong>Example:</strong></p>

      <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.ner.NerConverter">NerConverter</a> Scala docs for more details on the API.</p>

      <div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nerConverter</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_src"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
        <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_src"</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>
    </div>
    <div class="h3-box">

      <h2 id="norvig-spellchecker">Norvig SpellChecker</h2>

      <p>This annotator retrieves tokens and makes corrections automatically if not found in an English dictionary<br />
<strong>Output type:</strong> Token
<strong>Input types:</strong> Token
<strong>Inputs:</strong> Any text for corpus. A list of words for dictionary. A comma separated custom dictionary.
<strong>Train Data:</strong> train_corpus is a spark dataset of text content
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingApproach.scala">NorvigSweetingApproach</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingModel.scala">NorvigSweetingModel</a><br />
<strong>Functions:</strong></p>

      <ul>
        <li>setDictionary(path, tokenPattern, readAs, options): path to file with properly spelled words, tokenPattern is the regex pattern to identify them in text, readAs LINE_BY_LINE or SPARK_DATASET, with options passed to Spark reader if the latter is set.</li>
        <li>setCaseSensitive(boolean): defaults to false. Might affect accuracy</li>
        <li>setDoubleVariants(boolean): enables extra check for word combinations, more accuracy at performance</li>
        <li>setShortCircuit(boolean): faster but less accurate mode</li>
        <li>setWordSizeIgnore(int): Minimum size of word before moving on. Defaults to 3.</li>
        <li>setDupsLimit(int): Maximum duplicate of characters to account for. Defaults to 2.</li>
        <li>setReductLimit(int): Word reduction limit. Defaults to 3</li>
        <li>setIntersections(int): Hamming intersections to attempt. Defaults to 10.</li>
        <li>setVowelSwapLimit(int): Vowel swap attempts. Defaults to 6.</li>
      </ul>

      <p><strong>Example:</strong></p>

      <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.spell.norvig.NorvigSweetingApproach">NorvigSweetingApproach</a> Scala docs for more details on the API.</p>

      <div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spell_checker</span> <span class="o">=</span> <span class="n">NorvigSweetingApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"checked"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDictionary</span><span class="p">(</span><span class="s">"coca2017.txt"</span><span class="p">,</span> <span class="s">"[a-zA-Z]+"</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">symSpellChecker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NorvigSweetingApproach</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"checked"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setDictionary</span><span class="o">(</span><span class="s">"coca2017.txt"</span><span class="o">,</span> <span class="s">"[a-zA-Z]+"</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>
    </div>
    <div class="h3-box">

      <h2 id="symmetric-spellchecker">Symmetric SpellChecker</h2>

      <p>This spell checker is inspired on Symmetric Delete algorithm. It retrieves tokens and utilizes distance metrics to compute possible derived words<br />
<strong>Output type:</strong> Token<br />
<strong>Input types:</strong> Token  <br />
<strong>Inputs:</strong> Any text for corpus. A list of words for dictionary. A comma separated custom dictionary.     <br />
<strong>Train Data:</strong> train_corpus is a spark dataset of text content   <br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteApproach.scala">SymmetricDeleteApproach</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel.scala">SymmetricDeleteModel</a><br />
<strong>Functions:</strong></p>

      <ul>
        <li>setDictionary(path, tokenPattern, readAs, options): Optional dictionary of properly written words. If provided, significantly boosts spell checking performance</li>
        <li>setMaxEditDistance(distance): Maximum edit distance to calculate possible derived words. Defaults to 3.</li>
      </ul>

      <p><strong>Example:</strong></p>

      <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.spell.symmetric.SymmetricDeleteApproach">SymmetricDeleteApproach</a> Scala docs for more details on the API.</p>

      <div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spell_checker</span> <span class="o">=</span> <span class="n">SymmetricDeleteApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"spell"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_corpus</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">spellChecker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SymmetricDeleteApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"spell"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainCorpus</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>
    </div>
    <div class="h3-box">

      <h2 id="context-spellchecker">Context SpellChecker</h2>

      <p>Implements Noisy Channel Model Spell Algorithm. Correction candidates are extracted combining context information and word information<br />
<strong>Output type:</strong> Token<br />
<strong>Input types:</strong> Token<br />
<strong>Inputs:</strong> Any text for corpus. A list of words for dictionary. A comma separated custom dictionary.    <br />
<strong>Train Data:</strong> train_corpus is a spark dataset of text content  <br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerApproach.scala">ContextSpellCheckerApproach</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel.scala">ContextSpellCheckerModel</a><br />
<strong>Functions:</strong></p>

      <ul>
        <li>setLanguageModelClasses(languageModelClasses:Int): Number of classes to use during factorization of the softmax output in the LM. Defaults to 2000.</li>
        <li>setWordMaxDistance(dist:Int): Maximum distance for the generated candidates for every word. Defaults to 3.</li>
        <li>setMaxCandidates(candidates:Int): Maximum number of candidates for every word. Defaults to 6.</li>
        <li>setCaseStrategy(strategy:Int): What case combinations to try when generating candidates. ALL_UPPER_CASE = 0, FIRST_LETTER_CAPITALIZED = 1, ALL = 2. Defaults to 2.</li>
        <li>setErrorThreshold(threshold:Float): Threshold perplexity for a word to be considered as an error. Defaults to 10f.</li>
        <li>setTradeoff(alpha:Float): Tradeoff between the cost of a word error and a transition in the language model. Defaults to 18.0f.</li>
        <li>setMaxWindowLen(length:Integer): Maximum size for the window used to remember history prior to every correction. Defaults to 5.</li>
        <li>setGamma(g:Float): Controls the influence of individual word frequency in the decision.</li>
        <li>updateVocabClass(label:String, vocab:Array(String), append:boolean): Update existing vocabulary classes so they can cover new words. If append set to <code class="language-plaintext highlighter-rouge">false</code> overwrite vocabulary class in the model by new words, if <code class="language-plaintext highlighter-rouge">true</code> extends existing vocabulary class. Defaults to <code class="language-plaintext highlighter-rouge">true</code>.</li>
        <li>updateRegexClass(label:String, regex:String): Update existing regex rule for the class defined by regex.</li>
      </ul>

      <p>Train:</p>
      <ul>
        <li>setWeightedDistPath(weightedDistPath:String): The path to the file containing the weights for the levenshtein distance.</li>
        <li>setEpochs(epochs:Int): Number of epochs to train the language model. Defaults to 2.</li>
        <li>setInitialBatchSize(batchSize:Int): Batch size for the training in NLM. Defaults to 24.</li>
        <li>setInitialRate(initialRate:Float): Initial learning rate for the LM. Defaults to .7f.</li>
        <li>setFinalRate(finalRate:Float): Final learning rate for the LM. Defaults to 0.0005f.</li>
        <li>setValidationFraction(validationFraction:Float): Percentage of datapoints to use for validation. Defaults to .1f.</li>
        <li>setMinCount(minCount:Float): Min number of times a token should appear to be included in vocab. Defaults to 3.0f.</li>
        <li>setCompoundCount(compoundCount:Int): Min number of times a compound word should appear to be included in vocab. Defaults to 5.</li>
        <li>setClassCount(classCount:Int): Min number of times the word need to appear in corpus to not be considered of a special class. Defaults to 15.</li>
      </ul>

      <p><strong>Example:</strong></p>

      <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.spell.context.ContextSpellCheckerApproach">ContextSpellCheckerApproach</a> Scala docs for more details on the API.</p>

      <div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spell_checker</span> <span class="o">=</span> <span class="n">ContextSpellCheckerApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"spell"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_corpus</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">spellChecker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ContextSpellCheckerApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"spell"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainCorpus</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>
    </div>
    <div class="h3-box">

      <h2 id="dependency-parsers">Dependency Parsers</h2>

      <p>Dependency parser provides information about word relationship. For example, dependency parsing can tell you what the subjects and objects of a verb are, as well as which words are modifying (describing) the subject. This can help you find precise answers to specific questions.
The following diagram illustrates a dependency-style analysis using the standard graphical method favored in the dependency-parsing community.</p>

      <p><img src="\assets\images\dependency_parser.png" alt="Dependency Parser" /></p>

      <p>Relations among the words are illustrated above the sentence with directed, labeled arcs from heads to dependents. We call this a typed dependency structure because the labels are drawn from a fixed inventory of grammatical relations. It also includes a root node that explicitly marks the root of the tree, the head of the entire structure. [1]</p>

    </div>
    <div class="h3-box">

      <h2 id="untyped-dependency-parser-unlabeled-grammatical-relation">Untyped Dependency Parser (Unlabeled grammatical relation)</h2>

      <p>Unlabeled parser that finds a grammatical relation between two words in a sentence. Its input is a directory with dependency treebank files.<br />
<strong>Output type:</strong> Dependency<br />
<strong>Input types:</strong> Document, POS, Token<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproach.scala">DependencyParserApproach</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserModel.scala">DependencyParserModel</a><br />
<strong>Functions:</strong></p>

      <ul>
        <li>setNumberOfIterations: Number of iterations in training, converges to better accuracy</li>
        <li>setDependencyTreeBank: Dependency treebank folder with files in <a href="http://www.nltk.org/nltk_data/">Penn Treebank format</a></li>
        <li>conllU: Path to a file in <a href="https://universaldependencies.org/format.html">CoNLL-U format</a></li>
      </ul>

      <p><strong>Example:</strong></p>

      <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserApproach">DependencyParserApproach</a> Scala docs for more details on the API.</p>

      <div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">DependencyParserApproach</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependency"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setDependencyTreeBank</span><span class="p">(</span><span class="s">"file://parser/dependency_treebank"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setNumberOfIterations</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">dependencyParser</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DependencyParserApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependency"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDependencyTreeBank</span><span class="o">(</span><span class="s">"parser/dependency_treebank"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setNumberOfIterations</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>
    </div>
    <div class="h3-box">

      <h2 id="typed-dependency-parser-labeled-grammatical-relation">Typed Dependency Parser (Labeled grammatical relation)</h2>

      <p>Labeled parser that finds a grammatical relation between two words in a sentence. Its input is a CoNLL2009 or ConllU dataset.<br />
<strong>Output type:</strong> Labeled Dependency<br />
<strong>Input types:</strong> Token, POS, Dependency<br />
<strong>Reference:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserApproach.scala">TypedDependencyParserApproach</a> | <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserModel.scala">TypedDependencyParserModel</a><br />
<strong>Functions:</strong></p>

      <ul>
        <li>setNumberOfIterations: Number of iterations in training, converges to better accuracy</li>
        <li>setConll2009: Path to a file in <a href="https://ufal.mff.cuni.cz/conll2009-st/trial-data.html">CoNLL 2009 format</a></li>
        <li>setConllU: Path to a file in <a href="https://universaldependencies.org/format.html">CoNLL-U format</a></li>
      </ul>

      <p><strong>Example:</strong></p>

      <p>Refer to the <a href="https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.parser.typdep.TypedDependencyParserApproach">TypedDependencyParserApproach</a> Scala docs for more details on the API.</p>

      <div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">typed_dependency_parser</span> <span class="o">=</span> <span class="n">TypedDependencyParserApproach</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">,</span> <span class="s">"dependency"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"labdep"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setConll2009</span><span class="p">(</span><span class="s">"file://conll2009/eng.train"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setNumberOfIterations</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">typedDependencyParser</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TypedDependencyParserApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">,</span> <span class="s">"dependency"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"labdep"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setConll2009</span><span class="o">(</span><span class="s">"conll2009/eng.train"</span><span class="o">))</span>
</code></pre></div>        </div>

      </div>
    </div>
    <div class="h3-box">

      <h2 id="references">References</h2>

      <p>[1] Speech and Language Processing. Daniel Jurafsky &amp; James H. Martin. 2018</p>
    </div>
  </div>
</div>
</div><div class="d-print-none"><footer class="article__footer"><span class="footer_date">Last updated
      <time itemprop="dateModified" datetime="2021-02-01T00:00:00+00:00">Feb 01, 2021</time>
    </span><!-- start custom article footer snippet -->

<!-- end custom article footer snippet --></footer>

<script>


jQuery(document).ready(function(){  
    $( ".scala-button" ).click(function() {
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-scala" ).show();
        $(this).closest( ".tabs-box" ).find( ".language-python, .nlu-block" ).hide();
    });

    $( ".python-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-un-active').addClass( "code-selector-active" ); 

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');


        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-python" ).show();
        $(this).closest( ".tabs-box" ).find( ".nlu-block, .language-scala" ).hide();
    });

    $( ".nlu-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets        
        $(this).closest( ".tabs-box" ).find( ".language-python, .language-scala" ).hide();
        $(this).closest( ".tabs-box" ).find( ".nlu-block" ).show();
    });
});

function togglePython1() {

    //set current button to active class and remove unactive class
    $( ".python-button" ).addClass( "code-selector-active" );


    //toggle language snippets
    $( ".tabs-box .language-python" ).show() 
    $( ".tabs-box .nlu-block" ).hide()
    $( ".tabs-box .language-scala" ).hide()
}

function defer(method) { //wait until jquery ready
    if (window.jQuery) {
        method();
    } else {
        setTimeout(function() { defer(method) }, 15);
    }
}

defer(function () { // load inital language
    togglePython1()
});




</script>


<style>
  /* Remove Scrollbar from Code Segments */
.article__content .highlighter-rouge > .highlight > pre > code, .article__content figure.highlight > pre > code  {
    overflow: auto;
}



button.code-selector-active {
 background-color: white;
 color: #08c;
 font-weight: bold;
 border-width: 1px;
 padding-left: 12px;
 padding-right: 12px;
 width: 90px;
 padding-top: 6px;
 margin-right: 2px;

 border-bottom: none;

 position: relative;
 z-index: 2;
}

button.code-selector-un-active {
    background-color: white;
    padding-left: 12px;
    padding-right: 12px;
    width: 90px;
    margin-right: 2px;
    padding-top: 8px;
    position: relative;
    border-bottom: none;

   }

hr.code-selector-underlie {
    border-top: 1px solid;
    background-color: black;
    width: fill;
    height: 1px;
    margin-top: -3px;
    position: relative;

}

</style><div class="article__section-navigator clearfix"><div class="previous nav_link"><span>PREVIOUS</span><a href="/docs/en/transformers">Transformers</a></div><div class="next nav_link"><span>NEXT</span><a href="/docs/en/auxiliary">Helpers</a></div></div></div>

</div>
</div>

<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    $(function() {
      var $this ,$scroll;
      var $articleContent = $('.js-article-content');
      var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
      var scroll = hasSidebar ? '.js-page-main' : 'html, body';
      $scroll = $(scroll);

      $articleContent.find('.highlight').each(function() {
        $this = $(this);
        $this.attr('data-lang', $this.find('code').attr('data-lang'));
      });
      $articleContent.find('h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]').each(function() {
        $this = $(this);
        $this.append($('<a class="anchor d-print-none" aria-hidden="true"></a>').html('<i class="fas fa-anchor"></i>'));
      });
      $articleContent.on('click', '.anchor', function() {
        $scroll.scrollToAnchor('#' + $(this).parent().attr('id'), 400);
      });
    });
  });
})();
</script></div><section class="page__comments d-print-none"></section></article><!-- start custom main bottom snippet -->

<!-- end custom main bottom snippet --></div>
            </div></div></div><div class="page__footer d-print-none">
<footer class="footer py-4 js-page-footer">
  <div class="main"><div itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content=""><meta itemprop="url" content="/"></div><div class="site-info mt-2">
      <div>© 2021 John Snow Labs Inc.
        <a href="http://www.johnsnowlabs.com/terms-of-service">Terms of Service</a> | <a href="http://www.johnsnowlabs.com/privacy-policy/">Privacy Policy</a>
      </div>
    </div>
  </div>
</footer>

<script>

/* Responsive menu
	 ========================================================*/
jQuery(document).ready(function($) {
	jQuery('#responsive_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.top_navigation').toggleClass('open');
  });
  jQuery('#aside_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.js-col-aside').toggleClass('open');
      if (jQuery(window).width() <= 1023)
      {
        jQuery('.page__sidebar').toggleClass('open'); 
      }
  });
  jQuery('.toc--ellipsis a').click(function(e) {
    if (jQuery(window).width() <= 767)
      {
        jQuery('.js-col-aside').removeClass('open');
        jQuery('.page__sidebar').removeClass('open');     
        jQuery('#aside_menu').removeClass('close');  
      }       
  });
});

/*TABS*/
function openTabCall(cityName){
  // Declare all variables
  var i, tabcontent, tablinks;

  // Get all elements with class="tabcontent" and hide them
  tabcontent = document.getElementsByClassName("tabcontent");
  for (i = 0; i < tabcontent.length; i++) {
    tabcontent[i].style.display = "none";
  }

  // Get all elements with class="tablinks" and remove the class "active"
  tablinks = document.getElementsByClassName("tablinks");
  for (i = 0; i < tablinks.length; i++) {
    tablinks[i].className = tablinks[i].className.replace(" active", "");
  }

  // Show the current tab, and add an "active" class to the button that opened the tab
  document.getElementById(cityName).style.display = "block";
}

function openTab(evt, cityName) {
  openTabCall(cityName);
  evt.currentTarget.className += " active";
}

/*OPen by URL*/
$(document).ready(function () {  
  const tabName = (window.location.hash || '').replace('#', '');
  document.getElementById(tabName || 'opensource').click();
});

jQuery(document).ready(function(){
	jQuery('.tab-item').click(function(event) {		
		if (($(window).width() > 400) && ($(window).width() < 1199))
	    {
	    	jQuery('.tab-item').removeClass('open');
	        jQuery(this).toggleClass('open');
	    }
  });
  

});


 

</script></div></div>
    </div></div></div><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $body = $('body'), $window = $(window);
    var $pageRoot = $('.js-page-root'), $pageMain = $('.js-page-main');
    var activeCount = 0;
    function modal(options) {
      var $root = this, visible, onChange, hideWhenWindowScroll = false;
      var scrollTop;
      function setOptions(options) {
        var _options = options || {};
        visible = _options.initialVisible === undefined ? false : show;
        onChange = _options.onChange;
        hideWhenWindowScroll = _options.hideWhenWindowScroll;
      }
      function init() {
        setState(visible);
      }
      function setState(isShow) {
        if (isShow === visible) {
          return;
        }
        visible = isShow;
        if (visible) {
          activeCount++;
          scrollTop = $(window).scrollTop() || $pageMain.scrollTop();
          $root.addClass('modal--show');
          $pageMain.scrollTop(scrollTop);
          activeCount === 1 && ($pageRoot.addClass('show-modal'), $body.addClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.on('scroll', hide);
          $window.on('keyup', handleKeyup);
        } else {
          activeCount > 0 && activeCount--;
          $root.removeClass('modal--show');
          $window.scrollTop(scrollTop);
          activeCount === 0 && ($pageRoot.removeClass('show-modal'), $body.removeClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.off('scroll', hide);
          $window.off('keyup', handleKeyup);
        }
        onChange && onChange(visible);
      }
      function show() {
        setState(true);
      }
      function hide() {
        setState(false);
      }
      function handleKeyup(e) {
        // Char Code: 27  ESC
        if (e.which ===  27) {
          hide();
        }
      }
      setOptions(options);
      init();
      return {
        show: show,
        hide: hide,
        $el: $root
      };
    }
    $.fn.modal = modal;
  });
})();
</script><div class="modal modal--overflow page__search-modal d-print-none js-page-search-modal"><script>
(function () {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    // search panel
    var search = (window.search || (window.search = {}));
    var useDefaultSearchBox = window.useDefaultSearchBox === undefined ?
      true : window.useDefaultSearchBox ;

    var $searchModal = $('.js-page-search-modal');
    var $searchToggle = $('.js-search-toggle');
    var searchModal = $searchModal.modal({ onChange: handleModalChange, hideWhenWindowScroll: true });
    var modalVisible = false;
    search.searchModal = searchModal;

    var $searchBox = null;
    var $searchInput = null;
    var $searchClear = null;

    function getModalVisible() {
      return modalVisible;
    }
    search.getModalVisible = getModalVisible;

    function handleModalChange(visible) {
      modalVisible = visible;
      if (visible) {
        search.onShow && search.onShow();
        useDefaultSearchBox && $searchInput[0] && $searchInput[0].focus();
      } else {
        search.onShow && search.onHide();
        useDefaultSearchBox && $searchInput[0] && $searchInput[0].blur();
        setTimeout(function() {
          useDefaultSearchBox && ($searchInput.val(''), $searchBox.removeClass('not-empty'));
          search.clear && search.clear();
          window.pageAsideAffix && window.pageAsideAffix.refresh();
        }, 400);
      }
    }

    $searchToggle.on('click', function() {
      modalVisible ? searchModal.hide() : searchModal.show();
    });
    // Char Code: 83  S, 191 /
    $(window).on('keyup', function(e) {
      if (!modalVisible && !window.isFormElement(e.target || e.srcElement) && (e.which === 83 || e.which === 191)) {
        modalVisible || searchModal.show();
      }
    });

    if (useDefaultSearchBox) {
      $searchBox = $('.js-search-box');
      $searchInput = $searchBox.children('input');
      $searchClear = $searchBox.children('.js-icon-clear');
      search.getSearchInput = function() {
        return $searchInput.get(0);
      };
      search.getVal = function() {
        return $searchInput.val();
      };
      search.setVal = function(val) {
        $searchInput.val(val);
      };

      $searchInput.on('focus', function() {
        $(this).addClass('focus');
      });
      $searchInput.on('blur', function() {
        $(this).removeClass('focus');
      });
      $searchInput.on('input', window.throttle(function() {
        var val = $(this).val();
        if (val === '' || typeof val !== 'string') {
          search.clear && search.clear();
        } else {
          $searchBox.addClass('not-empty');
          search.onInputNotEmpty && search.onInputNotEmpty(val);
        }
      }, 400));
      $searchClear.on('click', function() {
        $searchInput.val(''); $searchBox.removeClass('not-empty');
        search.clear && search.clear();
      });
    }
  });
})();
</script><div class="search search--dark">
  <div class="main">
    <div class="search__header">Search Models and Pipelines</div>
    <div class="search-bar">
      <div class="search-box js-search-box">
        <div class="search-box__icon-search"><i class="fas fa-search"></i></div>
        <input type="text" />
        <div class="search-box__icon-clear js-icon-clear">
          <a><i class="fas fa-times"></i></a>
        </div>
      </div>
      <button class="button button--theme-dark button--pill search__cancel js-search-toggle">
        Cancel</button>
    </div>
    <div class="search-result js-search-result"></div>
  </div>
</div>
<script>var SOURCES = window.TEXT_VARIABLES.sources;
var PAHTS = window.TEXT_VARIABLES.paths;
window.Lazyload.js([SOURCES.jquery, PAHTS.search_js], function() {
  var search = (window.search || (window.search = {}));
  var searchData = window.TEXT_SEARCH_DATA ? initData(window.TEXT_SEARCH_DATA) : {};

  function memorize(f) {
    var cache = {};
    return function () {
      var key = Array.prototype.join.call(arguments, ',');
      if (key in cache) return cache[key];
      else return cache[key] = f.apply(this, arguments);
    };
  }

  function initData(data) {
    var _data = [], i, j, key, keys, cur;
    keys = Object.keys(data);
    for (i = 0; i < keys.length; i++) {
      key = keys[i], _data[key] = [];
      for (j = 0; j < data[key].length; j++) {
        cur = data[key][j];
        cur.title = window.decodeUrl(cur.title);
        cur.url = window.decodeUrl(cur.url);
        _data[key].push(cur);
      }
    }
    return _data;
  }

  /// search
  function searchByQuery(query) {
    var i, j, key, keys, cur, _title, result = {};
    keys = Object.keys(searchData);
    for (i = 0; i < keys.length; i++) {
      key = keys[i];
      for (j = 0; j < searchData[key].length; j++) {
        cur = searchData[key][j], _title = cur.title;
        if ((result[key] === undefined || result[key] && result[key].length < 4 )
          && _title.toLowerCase().indexOf(query.toLowerCase()) >= 0) {
          if (result[key] === undefined) {
            result[key] = [];
          }
          result[key].push(cur);
        }
      }
    }
    return result;
  }

  var renderHeader = memorize(function(header) {
    return $('<p class="search-result__header">' + header + '</p>');
  });

  var renderItem = function(index, title, url) {
    return $('<li class="search-result__item" data-index="' + index + '"><a class="button" href="' + url + '">' + title + '</a></li>');
  };

  function render(data) {
    if (!data) { return null; }
    var $root = $('<ul></ul>'), i, j, key, keys, cur, itemIndex = 0;
    keys = Object.keys(data);
    for (i = 0; i < keys.length; i++) {
      key = keys[i];
      $root.append(renderHeader(key));
      for (j = 0; j < data[key].length; j++) {
        cur = data[key][j];
        $root.append(renderItem(itemIndex++, cur.title, cur.url));
      }
    }
    return $root;
  }

  // search box
  var $result = $('.js-search-result'), $resultItems;
  var lastActiveIndex, activeIndex;

  function clear() {
    $result.html(null);
    $resultItems = $('.search-result__item'); activeIndex = 0;
  }
  function onInputNotEmpty(val) {
    $result.html(render(searchByQuery(val)));
    $resultItems = $('.search-result__item'); activeIndex = 0;
    $resultItems.eq(0).addClass('active');
  }

  search.clear = clear;
  search.onInputNotEmpty = onInputNotEmpty;

  function updateResultItems() {
    lastActiveIndex >= 0 && $resultItems.eq(lastActiveIndex).removeClass('active');
    activeIndex >= 0 && $resultItems.eq(activeIndex).addClass('active');
  }

  function moveActiveIndex(direction) {
    var itemsCount = $resultItems ? $resultItems.length : 0;
    if (itemsCount > 1) {
      lastActiveIndex = activeIndex;
      if (direction === 'up') {
        activeIndex = (activeIndex - 1 + itemsCount) % itemsCount;
      } else if (direction === 'down') {
        activeIndex = (activeIndex + 1 + itemsCount) % itemsCount;
      }
      updateResultItems();
    }
  }

  // Char Code: 13  Enter, 37  ⬅, 38  ⬆, 39  ➡, 40  ⬇
  $(window).on('keyup', function(e) {
    var modalVisible = search.getModalVisible && search.getModalVisible();
    if (modalVisible) {
      if (e.which === 38) {
        modalVisible && moveActiveIndex('up');
      } else if (e.which === 40) {
        modalVisible && moveActiveIndex('down');
      } else if (e.which === 13) {
        modalVisible && $resultItems && activeIndex >= 0 && $resultItems.eq(activeIndex).children('a')[0].click();
      }
    }
  });

  $result.on('mouseover', '.search-result__item > a', function() {
    var itemIndex = $(this).parent().data('index');
    itemIndex >= 0 && (lastActiveIndex = activeIndex, activeIndex = itemIndex, updateResultItems());
  });
});
</script></div></div>


<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function scrollToAnchor(anchor, duration, callback) {
      var $root = this;
      $root.animate({ scrollTop: $(anchor).position().top }, duration, function() {
        window.history.replaceState(null, '', window.location.href.split('#')[0] + anchor);
        callback && callback();
      });
    }
    $.fn.scrollToAnchor = scrollToAnchor;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function affix(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroll,
        offsetBottom = 0, scrollTarget = window, scroll = window.document, disabled = false, isOverallScroller = true,
        rootTop, rootLeft, rootHeight, scrollBottom, rootBottomTop,
        hasInit = false, curState;

      function setOptions(options) {
        var _options = options || {};
        _options.offsetBottom && (offsetBottom = _options.offsetBottom);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroll && (scroll = _options.scroll);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $scrollTarget = $(scrollTarget);
        isOverallScroller = window.isOverallScroller($scrollTarget[0]);
        $scroll = $(scroll);
      }
      function preCalc() {
        top();
        rootHeight = $root.outerHeight();
        rootTop = $root.offset().top + (isOverallScroller ? 0 :  $scrollTarget.scrollTop());
        rootLeft = $root.offset().left;
      }
      function calc(needPreCalc) {
        needPreCalc && preCalc();
        scrollBottom = $scroll.outerHeight() - offsetBottom - rootHeight;
        rootBottomTop = scrollBottom - rootTop;
      }
      function top() {
        if (curState !== 'top') {
          $root.removeClass('fixed').css({
            left: 0,
            top: 0
          });
          curState = 'top';
        }
      }
      function fixed() {
        if (curState !== 'fixed') {
          $root.addClass('fixed').css({
            left: rootLeft + 'px',
            top: 0
          });
          curState = 'fixed';
        }
      }
      function bottom() {
        if (curState !== 'bottom') {
          $root.removeClass('fixed').css({
            left: 0,
            top: rootBottomTop + 'px'
          });
          curState = 'bottom';
        }
      }
      function setState() {
        var scrollTop = $scrollTarget.scrollTop();
        if (scrollTop >= rootTop && scrollTop <= scrollBottom) {
          fixed();
        } else if (scrollTop < rootTop) {
          top();
        } else {
          bottom();
        }
      }
      function init() {
        if(!hasInit) {
          var interval, timeout;
          calc(true); setState();
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState();
          });
          $window.on('resize', function() {
            disabled || (calc(true), setState());
          });
          hasInit = true;
        }
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions,
        refresh: function() {
          calc(true, { animation: false }); setState();
        }
      };
    }
    $.fn.affix = affix;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function toc(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroller, $tocUl = $('<ul class="toc toc--ellipsis"></ul>'), $tocLi, $headings, $activeLast, $activeCur,
        selectors = 'h1,h2,h3', container = 'body', scrollTarget = window, scroller = 'html, body', disabled = false,
        headingsPos, scrolling = false, hasRendered = false, hasInit = false;

      function setOptions(options) {
        var _options = options || {};
        _options.selectors && (selectors = _options.selectors);
        _options.container && (container = _options.container);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroller && (scroller = _options.scroller);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $headings = $(container).find(selectors).filter('[id]');
        $scrollTarget = $(scrollTarget);
        $scroller = $(scroller);
      }
      function calc() {
        headingsPos = [];
        $headings.each(function() {
          headingsPos.push(Math.floor($(this).position().top));
        });
      }
      function setState(element, disabled) {
        var scrollTop = $scrollTarget.scrollTop(), i;
        if (disabled || !headingsPos || headingsPos.length < 1) { return; }
        if (element) {
          $activeCur = element;
        } else {
          for (i = 0; i < headingsPos.length; i++) {
            if (scrollTop >= headingsPos[i]) {
              $activeCur = $tocLi.eq(i);
            } else {
              $activeCur || ($activeCur = $tocLi.eq(i));
              break;
            }
          }
        }
        $activeLast && $activeLast.removeClass('active');
        ($activeLast = $activeCur).addClass('active');
      }
      function render() {
        if(!hasRendered) {
          $root.append($tocUl);
          $headings.each(function() {
            var $this = $(this);
            $tocUl.append($('<li></li>').addClass('toc-' + $this.prop('tagName').toLowerCase())
              .append($('<a></a>').text($this.text()).attr('href', '#' + $this.prop('id'))));
          });
          $tocLi = $tocUl.children('li');
          $tocUl.on('click', 'a', function(e) {
            e.preventDefault();
            var $this = $(this);
            scrolling = true;
            setState($this.parent());
            $scroller.scrollToAnchor($this.attr('href'), 400, function() {
              scrolling = false;
            });
          });
        }
        hasRendered = true;
      }
      function init() {
        var interval, timeout;
        if(!hasInit) {
          render(); calc(); setState(null, scrolling);
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState(null, scrolling);
          });
          $window.on('resize', window.throttle(function() {
            if (!disabled) {
              render(); calc(); setState(null, scrolling);
            }
          }, 100));
        }
        hasInit = true;
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions
      };
    }
    $.fn.toc = toc;
  });
})();
/*(function () {

})();*/
</script><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;

  window.Lazyload.js(SOURCES.jquery, function() {
    var $pageMask = $('.js-page-mask');
    var $pageRoot = $('.js-page-root');
    var $sidebarShow = $('.js-sidebar-show');
    var $sidebarHide = $('.js-sidebar-hide');

    function freeze(e) {
      if (e.target === $pageMask[0]) {
        e.preventDefault();
      }
    }
    function stopBodyScrolling(bool) {
      if (bool === true) {
        window.addEventListener('touchmove', freeze, { passive: false });
      } else {
        window.removeEventListener('touchmove', freeze, { passive: false });
      }
    }

    $sidebarShow.on('click', function() {
      stopBodyScrolling(true); $pageRoot.addClass('show-sidebar');
    });
    $sidebarHide.on('click', function() {
      stopBodyScrolling(false); $pageRoot.removeClass('show-sidebar');
    });
  });
})();
</script><script>
  /* toc must before affix, since affix need to konw toc' height. */(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  var TOC_SELECTOR = window.TEXT_VARIABLES.site.toc.selectors;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window);
    var $articleContent = $('.js-article-content');
    var $tocRoot = $('.js-toc-root'), $col2 = $('.js-col-aside');
    var toc;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
    var hasToc = $articleContent.find(TOC_SELECTOR).length > 0;

    function disabled() {
      return $col2.css('display') === 'none' || !hasToc;
    }

    tocDisabled = disabled();

    toc = $tocRoot.toc({
      selectors: TOC_SELECTOR,
      container: $articleContent,
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      tocDisabled = disabled();
      toc && toc.setOptions({
        disabled: tocDisabled
      });
    }, 100));

  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window), $pageFooter = $('.js-page-footer');
    var $pageAside = $('.js-page-aside');
    var affix;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');

    affix = $pageAside.affix({
      offsetBottom: $pageFooter.outerHeight(),
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      scroll: hasSidebar ? $('.js-page-main').children() : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      affix && affix.setOptions({
        disabled: tocDisabled
      });
    }, 100));

    window.pageAsideAffix = affix;
  });
})();
</script><script>
  window.Lazyload.js(['https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js', 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js'], function() {
    var $canvas = null, $this = null, _ctx = null, _text = '';
    $('.language-chart').each(function(){
      $this = $(this);
      $canvas = $('<canvas></canvas>');
      _text = $this.text();
      $this.text('').append($canvas);
      _ctx = $canvas.get(0).getContext('2d');
      (_ctx && _text) && (new Chart(_ctx, JSON.parse(_text)) && $this.attr('data-processed', true));
    });
  });
</script><script type="text/x-mathjax-config">
	var _config = { tex2jax: {
		inlineMath: [['$','$'], ['\\(','\\)']]
	}};_config.TeX = { equationNumbers: { autoNumber: "all" } };MathJax.Hub.Config(_config);
</script>
<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script>
  window.Lazyload.js('https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js', function() {
    mermaid.initialize({
      startOnLoad: true
    });
    mermaid.init(undefined, '.language-mermaid');
  });
</script>
    </div>
    <script>(function () {
  var $root = document.getElementsByClassName('root')[0];
  if (window.hasEvent('touchstart')) {
    $root.dataset.isTouch = true;
    document.addEventListener('touchstart', function(){}, false);
  }
})();
</script>
  </body>
</html>